- At the core of your interactions lie training techniques. **These determine the way the model generates answers**.
- Understanding the spectrum of 1. zero-shot 2. one-shot 3. and few-shot learning is crucial.
- They represent the degree of examples or context we provide ChatGPT before asking our main question. 

1. Zero-shot learning is when we throw a question or task at ChatGPT without providing any prior examples
2. One-shot is the middle ground. Think of it as showing someone how to do a task once and then expecting them to replicate it
3. Few-shot learning is where we arm ChatGPT with multiple examples before posing our main query.
   
![image](https://github.com/user-attachments/assets/f3f7e17e-0d54-49e0-a0cf-4f3cbdf4dbcf)
