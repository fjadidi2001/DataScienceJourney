- At the core of your interactions lie training techniques. **These determine the way the model generates answers**.
- Understanding the spectrum of 1. zero-shot 2. one-shot 3. and few-shot learning is crucial.
- They represent the degree of examples or context we provide ChatGPT before asking our main question. 

1. Zero-shot learning is when we throw a question or task at ChatGPT without providing any prior examples
2. One-shot is the middle ground. Think of it as showing someone how to do a task once and then expecting them to replicate it
3. Few-shot learning is where we arm ChatGPT with multiple examples before posing our main query.
   
![image](https://github.com/user-attachments/assets/f3f7e17e-0d54-49e0-a0cf-4f3cbdf4dbcf)



<br>

Chain of Thought Prompting (COT) is an advanced technique that takes training a step further.
<br>
It mirrors the way we are, as humans, approach problem-solving: by breaking down complex tasks into manageable steps.



 **using Zero-shot for a quick reply, One-shot for guided responses, Few-shot for pattern-driven answers, or COT for methodical solutions**
