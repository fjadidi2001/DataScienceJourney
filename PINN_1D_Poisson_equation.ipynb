{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ/hzdE8dPyo5GUnZ/58yp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/DataScienceJourney/blob/master/PINN_1D_Poisson_equation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Physics-Informed Neural Networks (PINNs) are a type of neural network that leverages both data and physical laws (represented by differential equations) to model complex systems. They are particularly useful for solving partial differential equations (PDEs), where traditional numerical methods may be computationally expensive or infeasible. PINNs incorporate these physical laws as part of the loss function, allowing the network to not only fit data but also adhere to the governing physics."
      ],
      "metadata": {
        "id": "fdYY_WJ4AU7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps to Solve the Poisson Equation Using PINNs\n",
        "1. Define the Neural Network: A fully connected neural network is used to approximate the solution ùë¢(ùë•,ùë¶) of the Poisson equation.\n",
        "2. Formulate the PDE Residual: The residual of the Poisson equation is derived by substituting the network's output into the equation.\n",
        "3. Define the Loss Function: The loss function consists of two parts:\n",
        "- PDE Loss: Ensures that the network's output satisfies the Poisson equation.\n",
        "- Boundary Condition Loss: Ensures that the network satisfies the boundary conditions.\n",
        "4. Train the Network: The network is trained by minimizing the combined loss.\n"
      ],
      "metadata": {
        "id": "dvO8XxmvSD_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Define the neural network model\n",
        "class PINN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(PINN, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(20, activation='tanh')\n",
        "        self.dense2 = tf.keras.layers.Dense(20, activation='tanh')\n",
        "        self.dense3 = tf.keras.layers.Dense(20, activation='tanh')\n",
        "        self.dense4 = tf.keras.layers.Dense(1, activation=None)\n",
        "\n",
        "    def call(self, X):\n",
        "        x = self.dense1(X)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dense3(x)\n",
        "        return self.dense4(x)\n",
        "\n",
        "# Step 2: Define the physics-informed loss function\n",
        "def pde_loss(model, X):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        tape.watch(X)\n",
        "        u = model(X)\n",
        "        u_x = tape.gradient(u, X)[:, 0:1]\n",
        "        u_y = tape.gradient(u, X)[:, 1:2]\n",
        "        u_xx = tape.gradient(u_x, X)[:, 0:1]\n",
        "        u_yy = tape.gradient(u_y, X)[:, 1:2]\n",
        "    del tape\n",
        "    # Poisson equation residual (Œîu = f(x, y))\n",
        "    residual = u_xx + u_yy + 1.0  # assuming f(x, y) = -1\n",
        "    return tf.reduce_mean(tf.square(residual))\n",
        "\n",
        "# Step 3: Define the boundary condition loss\n",
        "def boundary_loss(model, X_boundary):\n",
        "    u_boundary = model(X_boundary)\n",
        "    return tf.reduce_mean(tf.square(u_boundary))  # u = 0 on boundary\n",
        "\n",
        "# Step 4: Total loss function\n",
        "def total_loss(model, X, X_boundary):\n",
        "    return pde_loss(model, X) + boundary_loss(model, X_boundary)\n",
        "\n",
        "# Step 5: Generate training data (collocation points and boundary points)\n",
        "def generate_training_data(N_collocation, N_boundary):\n",
        "    # Collocation points inside the domain\n",
        "    X_collocation = np.random.rand(N_collocation, 2)\n",
        "    # Boundary points\n",
        "    X_boundary = np.vstack([\n",
        "        np.random.rand(N_boundary, 1), np.zeros((N_boundary, 1)),\n",
        "        np.zeros((N_boundary, 1)), np.random.rand(N_boundary, 1),\n",
        "        np.ones((N_boundary, 1)), np.random.rand(N_boundary, 1),\n",
        "        np.random.rand(N_boundary, 1), np.ones((N_boundary, 1))\n",
        "    ]).T\n",
        "    return X_collocation, X_boundary\n",
        "\n",
        "# Step 6: Train the PINN\n",
        "def train_pinn(model, X, X_boundary, epochs, learning_rate):\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    for epoch in range(epochs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss_value = total_loss(model, X, X_boundary)\n",
        "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f'Epoch {epoch}, Loss: {loss_value.numpy()}')\n",
        "\n",
        "# Step 7: Visualize the solution\n",
        "def plot_solution(model):\n",
        "    x = np.linspace(0, 1, 100)\n",
        "    y = np.linspace(0, 1, 100)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    X_flat = X.flatten().reshape(-1, 1)\n",
        "    Y_flat = Y.flatten().reshape(-1, 1)\n",
        "    U_pred = model(np.hstack([X_flat, Y_flat])).numpy().reshape(100, 100)\n",
        "\n",
        "    plt.contourf(X, Y, U_pred, 20, cmap='viridis')\n",
        "    plt.colorbar()\n",
        "    plt.title('PINN Solution of the Poisson Equation')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('y')\n",
        "    plt.show()\n",
        "\n",
        "# Main script\n",
        "N_collocation = 10000  # Number of collocation points\n",
        "N_boundary = 400       # Number of boundary points\n",
        "epochs = 5000          # Number of training epochs\n",
        "learning_rate = 0.001  # Learning rate\n",
        "\n",
        "X_collocation, X_boundary = generate_training_data(N_collocation, N_boundary)\n",
        "model = PINN()\n",
        "train_pinn(model, X_collocation, X_boundary, epochs, learning_rate)\n",
        "plot_solution(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "gvki5CKpNgLF",
        "outputId": "9bbc7904-db5f-47c0-8501-51f02d0f8119"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Passed in object [[0.07733232 0.94513172]\n [0.37562977 0.04169731]\n [0.84557048 0.92807062]\n ...\n [0.80995805 0.86451098]\n [0.31313663 0.91349819]\n [0.68428918 0.92389123]] of type 'ndarray', not tf.Tensor or tf.Variable or ExtensionType.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1d12d04b62b9>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mX_collocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_boundary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_collocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_boundary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPINN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mtrain_pinn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_collocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_boundary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0mplot_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-1d12d04b62b9>\u001b[0m in \u001b[0;36mtrain_pinn\u001b[0;34m(model, X, X_boundary, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_boundary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-1d12d04b62b9>\u001b[0m in \u001b[0;36mtotal_loss\u001b[0;34m(model, X, X_boundary)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Step 4: Total loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_boundary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpde_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mboundary_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_boundary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Step 5: Generate training data (collocation points and boundary points)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-1d12d04b62b9>\u001b[0m in \u001b[0;36mpde_loss\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpde_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mu_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mwatch\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    871\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0mencounters\u001b[0m \u001b[0msomething\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \"\"\"\n\u001b[0;32m--> 873\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_extract_tensors_and_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbackprop_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsTrainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         logging.log_first_n(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_extract_tensors_and_variables\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    698\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_extract_tensors_and_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m       raise ValueError(f\"Passed in object {obj} of type {type(obj).__name__!r}\"\n\u001b[0m\u001b[1;32m    701\u001b[0m                        f\", not tf.Tensor or tf.Variable or ExtensionType.\")\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Passed in object [[0.07733232 0.94513172]\n [0.37562977 0.04169731]\n [0.84557048 0.92807062]\n ...\n [0.80995805 0.86451098]\n [0.31313663 0.91349819]\n [0.68428918 0.92389123]] of type 'ndarray', not tf.Tensor or tf.Variable or ExtensionType."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S7HtGYrsSDh7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}