{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBnkYcrGhEgwaiwDTSXGWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/DataScienceJourney/blob/master/Face_March2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U3pZpDHExvnY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "df6263c4-2e63-40ec-a066-31970ded121f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'roboflow'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bb0160cda927>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mroboflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'roboflow'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from roboflow import Roboflow\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Connect to Roboflow and download dataset\n",
        "rf = Roboflow(api_key=\"2IGtFaicFMGaMwb2mX8A\")\n",
        "project = rf.workspace(\"mohamed-traore-2ekkp\").project(\"face-detection-mik1i\")\n",
        "version = project.version(25)\n",
        "\n",
        "# Download the dataset in YOLOv8 format\n",
        "version.download(\"yolov8\")\n",
        "\n",
        "# Set paths\n",
        "dataset_path = \"./face-detection-mik1i-25\"\n",
        "train_yaml = os.path.join(dataset_path, \"data.yaml\")\n",
        "\n",
        "# Train YOLOv8 model\n",
        "def train_yolo_model(yaml_path, epochs=50, imgsz=640):\n",
        "    # Initialize YOLOv8 model (can be 'yolov8n.pt', 'yolov8s.pt', 'yolov8m.pt', 'yolov8l.pt', 'yolov8x.pt')\n",
        "    model = YOLO('yolov8n.pt')  # Start with a pre-trained model\n",
        "\n",
        "    # Train the model\n",
        "    results = model.train(\n",
        "        data=yaml_path,\n",
        "        epochs=epochs,\n",
        "        imgsz=imgsz,\n",
        "        patience=10,  # Early stopping patience\n",
        "        batch=16,\n",
        "        device=0 if torch.cuda.is_available() else 'cpu',\n",
        "        name=\"face_detection_model\"\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def detect_faces(model, image_path, conf_threshold=0.25):\n",
        "    # Load image\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not load image at {image_path}\")\n",
        "        return None\n",
        "\n",
        "    # Run inference\n",
        "    results = model(img, conf=conf_threshold)\n",
        "\n",
        "    # Get detections\n",
        "    detections = results[0]\n",
        "\n",
        "    # Convert BGR to RGB for matplotlib\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Draw bounding boxes\n",
        "    for detection in detections.boxes.data.tolist():\n",
        "        x1, y1, x2, y2, confidence, class_id = detection\n",
        "\n",
        "        # Only process if confidence is above threshold\n",
        "        if confidence >= conf_threshold:\n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(img_rgb,\n",
        "                         (int(x1), int(y1)),\n",
        "                         (int(x2), int(y2)),\n",
        "                         (0, 255, 0), 2)\n",
        "\n",
        "            # Add label\n",
        "            label = f\"Face: {confidence:.2f}\"\n",
        "            cv2.putText(img_rgb, label, (int(x1), int(y1) - 10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    return img_rgb, detections\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    import torch\n",
        "\n",
        "    # Train the model (or load a pre-trained one)\n",
        "    try:\n",
        "        # Try to load existing model first\n",
        "        model_path = './runs/detect/face_detection_model/weights/best.pt'\n",
        "        if os.path.exists(model_path):\n",
        "            model = YOLO(model_path)\n",
        "            print(\"Loaded pre-trained model from\", model_path)\n",
        "        else:\n",
        "            print(\"Training new model...\")\n",
        "            model = train_yolo_model(train_yaml, epochs=30)\n",
        "            print(\"Model training complete\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in model training/loading: {e}\")\n",
        "        exit(1)\n",
        "\n",
        "    # Define a function to process a directory of images\n",
        "    def process_directory(directory_path, output_dir='./output_images'):\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Get all image files\n",
        "        valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
        "        image_files = [f for f in os.listdir(directory_path)\n",
        "                      if os.path.isfile(os.path.join(directory_path, f)) and\n",
        "                      os.path.splitext(f)[1].lower() in valid_extensions]\n",
        "\n",
        "        print(f\"Found {len(image_files)} images to process\")\n",
        "\n",
        "        for img_file in image_files:\n",
        "            img_path = os.path.join(directory_path, img_file)\n",
        "            try:\n",
        "                print(f\"Processing {img_file}...\")\n",
        "                img_rgb, detections = detect_faces(model, img_path)\n",
        "\n",
        "                if img_rgb is not None:\n",
        "                    # Save the output image\n",
        "                    output_path = os.path.join(output_dir, f\"detected_{img_file}\")\n",
        "                    plt.figure(figsize=(10, 8))\n",
        "                    plt.imshow(img_rgb)\n",
        "                    plt.axis('off')\n",
        "                    plt.savefig(output_path)\n",
        "                    plt.close()\n",
        "\n",
        "                    # Count detections\n",
        "                    boxes = detections.boxes\n",
        "                    print(f\"  Detected {len(boxes)} faces in {img_file}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Error processing {img_file}: {e}\")\n",
        "\n",
        "    # Example: Process test directory\n",
        "    test_dir = os.path.join(dataset_path, \"test\", \"images\")\n",
        "    process_directory(test_dir)\n",
        "\n",
        "    # You can also process a single image\n",
        "    def process_single_image(image_path):\n",
        "        img_rgb, detections = detect_faces(model, image_path)\n",
        "        if img_rgb is not None:\n",
        "            plt.figure(figsize=(12, 10))\n",
        "            plt.imshow(img_rgb)\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"Face Detection - Found {len(detections.boxes)} faces\")\n",
        "            plt.show()\n",
        "\n",
        "    # Uncomment to process a specific image\n",
        "    # process_single_image(\"path/to/your/image.jpg\")"
      ]
    }
  ]
}