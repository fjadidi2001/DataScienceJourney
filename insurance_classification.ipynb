{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNT9HooRHScBYUaynMRPqLF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/DataScienceJourney/blob/master/insurance_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHm7dCnH1rDf",
        "outputId": "792f467d-7e47-4ad4-e61f-f6b616609a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "First few rows of the dataset:\n",
            "   Duration  Insured.age Insured.sex  Car.age  Marital  Car.use  Credit.score  \\\n",
            "0       366           45        Male       -1  Married  Commute         609.0   \n",
            "1       182           44      Female        3  Married  Commute         575.0   \n",
            "2       184           48      Female        6  Married  Commute         847.0   \n",
            "3       183           71        Male        6  Married  Private         842.0   \n",
            "4       183           84        Male       10  Married  Private         856.0   \n",
            "\n",
            "  Region  Annual.miles.drive  Years.noclaims  ...  Left.turn.intensity10  \\\n",
            "0  Urban             6213.71              25  ...                    1.0   \n",
            "1  Urban            12427.42              20  ...                   58.0   \n",
            "2  Urban            12427.42              14  ...                    0.0   \n",
            "3  Urban             6213.71              43  ...                    0.0   \n",
            "4  Urban             6213.71              65  ...                    2.0   \n",
            "\n",
            "   Left.turn.intensity11  Left.turn.intensity12  Right.turn.intensity08  \\\n",
            "0                    0.0                    0.0                     3.0   \n",
            "1                   24.0                   11.0                  1099.0   \n",
            "2                    0.0                    0.0                     0.0   \n",
            "3                    0.0                    0.0                     0.0   \n",
            "4                    0.0                    0.0                   325.0   \n",
            "\n",
            "   Right.turn.intensity09  Right.turn.intensity10  Right.turn.intensity11  \\\n",
            "0                     1.0                     0.0                     0.0   \n",
            "1                   615.0                   219.0                   101.0   \n",
            "2                     0.0                     0.0                     0.0   \n",
            "3                     0.0                     0.0                     0.0   \n",
            "4                   111.0                    18.0                     4.0   \n",
            "\n",
            "   Right.turn.intensity12  NB_Claim    AMT_Claim  \n",
            "0                     0.0         1  5100.171753  \n",
            "1                    40.0         1   883.554840  \n",
            "2                     0.0         0     0.000000  \n",
            "3                     0.0         0     0.000000  \n",
            "4                     2.0         0     0.000000  \n",
            "\n",
            "[5 rows x 52 columns]\n",
            "\n",
            "Dataset information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 52 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   Duration                100000 non-null  int64  \n",
            " 1   Insured.age             100000 non-null  int64  \n",
            " 2   Insured.sex             100000 non-null  object \n",
            " 3   Car.age                 100000 non-null  int64  \n",
            " 4   Marital                 100000 non-null  object \n",
            " 5   Car.use                 100000 non-null  object \n",
            " 6   Credit.score            100000 non-null  float64\n",
            " 7   Region                  100000 non-null  object \n",
            " 8   Annual.miles.drive      100000 non-null  float64\n",
            " 9   Years.noclaims          100000 non-null  int64  \n",
            " 10  Territory               100000 non-null  int64  \n",
            " 11  Annual.pct.driven       100000 non-null  float64\n",
            " 12  Total.miles.driven      100000 non-null  float64\n",
            " 13  Pct.drive.mon           100000 non-null  float64\n",
            " 14  Pct.drive.tue           100000 non-null  float64\n",
            " 15  Pct.drive.wed           100000 non-null  float64\n",
            " 16  Pct.drive.thr           100000 non-null  float64\n",
            " 17  Pct.drive.fri           100000 non-null  float64\n",
            " 18  Pct.drive.sat           100000 non-null  float64\n",
            " 19  Pct.drive.sun           100000 non-null  float64\n",
            " 20  Pct.drive.2hrs          100000 non-null  float64\n",
            " 21  Pct.drive.3hrs          100000 non-null  float64\n",
            " 22  Pct.drive.4hrs          100000 non-null  float64\n",
            " 23  Pct.drive.wkday         100000 non-null  float64\n",
            " 24  Pct.drive.wkend         100000 non-null  float64\n",
            " 25  Pct.drive.rush am       100000 non-null  float64\n",
            " 26  Pct.drive.rush pm       100000 non-null  float64\n",
            " 27  Avgdays.week            100000 non-null  float64\n",
            " 28  Accel.06miles           100000 non-null  float64\n",
            " 29  Accel.08miles           100000 non-null  float64\n",
            " 30  Accel.09miles           100000 non-null  float64\n",
            " 31  Accel.11miles           100000 non-null  float64\n",
            " 32  Accel.12miles           100000 non-null  float64\n",
            " 33  Accel.14miles           100000 non-null  float64\n",
            " 34  Brake.06miles           100000 non-null  float64\n",
            " 35  Brake.08miles           100000 non-null  float64\n",
            " 36  Brake.09miles           100000 non-null  float64\n",
            " 37  Brake.11miles           100000 non-null  float64\n",
            " 38  Brake.12miles           100000 non-null  float64\n",
            " 39  Brake.14miles           100000 non-null  float64\n",
            " 40  Left.turn.intensity08   100000 non-null  float64\n",
            " 41  Left.turn.intensity09   100000 non-null  float64\n",
            " 42  Left.turn.intensity10   100000 non-null  float64\n",
            " 43  Left.turn.intensity11   100000 non-null  float64\n",
            " 44  Left.turn.intensity12   100000 non-null  float64\n",
            " 45  Right.turn.intensity08  100000 non-null  float64\n",
            " 46  Right.turn.intensity09  100000 non-null  float64\n",
            " 47  Right.turn.intensity10  100000 non-null  float64\n",
            " 48  Right.turn.intensity11  100000 non-null  float64\n",
            " 49  Right.turn.intensity12  100000 non-null  float64\n",
            " 50  NB_Claim                100000 non-null  int64  \n",
            " 51  AMT_Claim               100000 non-null  float64\n",
            "dtypes: float64(42), int64(6), object(4)\n",
            "memory usage: 39.7+ MB\n",
            "None\n",
            "\n",
            "Checking for missing values:\n",
            "Duration                  0\n",
            "Insured.age               0\n",
            "Insured.sex               0\n",
            "Car.age                   0\n",
            "Marital                   0\n",
            "Car.use                   0\n",
            "Credit.score              0\n",
            "Region                    0\n",
            "Annual.miles.drive        0\n",
            "Years.noclaims            0\n",
            "Territory                 0\n",
            "Annual.pct.driven         0\n",
            "Total.miles.driven        0\n",
            "Pct.drive.mon             0\n",
            "Pct.drive.tue             0\n",
            "Pct.drive.wed             0\n",
            "Pct.drive.thr             0\n",
            "Pct.drive.fri             0\n",
            "Pct.drive.sat             0\n",
            "Pct.drive.sun             0\n",
            "Pct.drive.2hrs            0\n",
            "Pct.drive.3hrs            0\n",
            "Pct.drive.4hrs            0\n",
            "Pct.drive.wkday           0\n",
            "Pct.drive.wkend           0\n",
            "Pct.drive.rush am         0\n",
            "Pct.drive.rush pm         0\n",
            "Avgdays.week              0\n",
            "Accel.06miles             0\n",
            "Accel.08miles             0\n",
            "Accel.09miles             0\n",
            "Accel.11miles             0\n",
            "Accel.12miles             0\n",
            "Accel.14miles             0\n",
            "Brake.06miles             0\n",
            "Brake.08miles             0\n",
            "Brake.09miles             0\n",
            "Brake.11miles             0\n",
            "Brake.12miles             0\n",
            "Brake.14miles             0\n",
            "Left.turn.intensity08     0\n",
            "Left.turn.intensity09     0\n",
            "Left.turn.intensity10     0\n",
            "Left.turn.intensity11     0\n",
            "Left.turn.intensity12     0\n",
            "Right.turn.intensity08    0\n",
            "Right.turn.intensity09    0\n",
            "Right.turn.intensity10    0\n",
            "Right.turn.intensity11    0\n",
            "Right.turn.intensity12    0\n",
            "NB_Claim                  0\n",
            "AMT_Claim                 0\n",
            "dtype: int64\n",
            "\n",
            "Basic statistics:\n",
            "            Duration    Insured.age        Car.age   Credit.score  \\\n",
            "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
            "mean      314.204060      51.378950       5.639720     800.888870   \n",
            "std        79.746222      15.467075       4.062135      83.382316   \n",
            "min        27.000000      16.000000      -2.000000     422.000000   \n",
            "25%       200.000000      39.000000       2.000000     766.000000   \n",
            "50%       365.000000      51.000000       5.000000     825.000000   \n",
            "75%       366.000000      63.000000       8.000000     856.000000   \n",
            "max       366.000000     103.000000      20.000000     900.000000   \n",
            "\n",
            "       Annual.miles.drive  Years.noclaims      Territory  Annual.pct.driven  \\\n",
            "count       100000.000000   100000.000000  100000.000000      100000.000000   \n",
            "mean          9124.122908       28.839960      56.531390           0.502294   \n",
            "std           3826.144730       16.123717      24.036518           0.299189   \n",
            "min              0.000000        0.000000      11.000000           0.002740   \n",
            "25%           6213.710000       15.000000      35.000000           0.249315   \n",
            "50%           7456.452000       29.000000      62.000000           0.490411   \n",
            "75%          12427.420000       41.000000      78.000000           0.753425   \n",
            "max          56731.172300       79.000000      91.000000           1.000000   \n",
            "\n",
            "       Total.miles.driven  Pct.drive.mon  ...  Left.turn.intensity10  \\\n",
            "count       100000.000000  100000.000000  ...          100000.000000   \n",
            "mean          4833.575303       0.139365  ...             551.574010   \n",
            "std           4545.943016       0.042807  ...           14687.929802   \n",
            "min              0.095298       0.000000  ...               0.000000   \n",
            "25%           1529.897500       0.120894  ...               0.000000   \n",
            "50%           3468.287765       0.137909  ...               3.000000   \n",
            "75%           6779.876842       0.155203  ...              30.000000   \n",
            "max          47282.603936       0.998172  ...          794380.000000   \n",
            "\n",
            "       Left.turn.intensity11  Left.turn.intensity12  Right.turn.intensity08  \\\n",
            "count          100000.000000          100000.000000           100000.000000   \n",
            "mean              487.340690             447.758420              843.461830   \n",
            "std             14198.331308           13719.790281            11630.185503   \n",
            "min                 0.000000               0.000000                0.000000   \n",
            "25%                 0.000000               0.000000               11.000000   \n",
            "50%                 1.000000               0.000000              122.000000   \n",
            "75%                 9.000000               2.000000              680.000000   \n",
            "max            793926.000000          793170.000000           841210.000000   \n",
            "\n",
            "       Right.turn.intensity09  Right.turn.intensity10  Right.turn.intensity11  \\\n",
            "count           100000.000000           100000.000000           100000.000000   \n",
            "mean               565.056100              326.654840              246.713120   \n",
            "std              10657.402935             9460.244357             8977.569994   \n",
            "min                  0.000000                0.000000                0.000000   \n",
            "25%                  3.000000                0.000000                0.000000   \n",
            "50%                 43.000000                7.000000                2.000000   \n",
            "75%                321.000000               81.000000               27.000000   \n",
            "max             841207.000000           841200.000000           841176.000000   \n",
            "\n",
            "       Right.turn.intensity12      NB_Claim      AMT_Claim  \n",
            "count           100000.000000  100000.00000  100000.000000  \n",
            "mean               198.753690       0.04494     137.602253  \n",
            "std               8585.177049       0.21813    1264.320056  \n",
            "min                  0.000000       0.00000       0.000000  \n",
            "25%                  0.000000       0.00000       0.000000  \n",
            "50%                  0.000000       0.00000       0.000000  \n",
            "75%                  9.000000       0.00000       0.000000  \n",
            "max             841144.000000       3.00000  104074.886700  \n",
            "\n",
            "[8 rows x 48 columns]\n",
            "\n",
            "Distribution of ClaimYN:\n",
            "ClaimYN\n",
            "0    97.302\n",
            "1     2.698\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Absolute counts:\n",
            "ClaimYN\n",
            "0    97302\n",
            "1     2698\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Load the dataset\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify file path\n",
        "file_path = '/content/drive/My Drive/telematics_syn.csv'\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Explore the data\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(data.head())\n",
        "print(\"\\nDataset information:\")\n",
        "print(data.info())\n",
        "print(\"\\nChecking for missing values:\")\n",
        "print(data.isnull().sum())\n",
        "print(\"\\nBasic statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Step 3: Create target variable ClaimYN\n",
        "data['ClaimYN'] = ((data['NB_Claim'] >= 1) & (data['AMT_Claim'] >= 1000)).astype(int)\n",
        "\n",
        "# Display distribution of ClaimYN\n",
        "print(\"\\nDistribution of ClaimYN:\")\n",
        "print(data['ClaimYN'].value_counts(normalize=True) * 100)\n",
        "print(\"\\nAbsolute counts:\")\n",
        "print(data['ClaimYN'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Print initial column count\n",
        "print(\"Initial number of columns:\", len(data.columns))\n",
        "\n",
        "# Separate features and target\n",
        "# Exclude NB_Claim and AMT_Claim as they were used to create the target\n",
        "features = data.drop(['ClaimYN', 'NB_Claim', 'AMT_Claim'], axis=1)\n",
        "print(\"\\nNumber of columns after dropping target and claim columns:\", len(features.columns))\n",
        "\n",
        "# Print categorical columns unique values\n",
        "print(\"\\nUnique values in categorical columns:\")\n",
        "categorical_columns = ['Insured.sex', 'Marital', 'Car.use', 'Region']\n",
        "for col in categorical_columns:\n",
        "    print(f\"{col}: {features[col].unique()}\")\n",
        "\n",
        "# Convert categorical variables to numeric using one-hot encoding\n",
        "features = pd.get_dummies(features, columns=categorical_columns)\n",
        "print(\"\\nColumns after one-hot encoding:\")\n",
        "print(features.columns.tolist())\n",
        "print(\"\\nTotal number of columns after encoding:\", len(features.columns))\n",
        "\n",
        "X = features\n",
        "y = data['ClaimYN']\n",
        "\n",
        "# Proceed with train-test split and SMOTE\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Print final shapes\n",
        "print(\"\\nFinal dataset shapes:\")\n",
        "print(f\"Original features: {X.shape}\")\n",
        "print(f\"X_train_balanced: {X_train_balanced.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hFfY_du2wNB",
        "outputId": "2fcf86df-9369-4ebe-e532-756fe80acf17"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of columns: 53\n",
            "\n",
            "Number of columns after dropping target and claim columns: 50\n",
            "\n",
            "Unique values in categorical columns:\n",
            "Insured.sex: ['Male' 'Female']\n",
            "Marital: ['Married' 'Single']\n",
            "Car.use: ['Commute' 'Private' 'Commercial' 'Farmer']\n",
            "Region: ['Urban' 'Rural']\n",
            "\n",
            "Columns after one-hot encoding:\n",
            "['Duration', 'Insured.age', 'Car.age', 'Credit.score', 'Annual.miles.drive', 'Years.noclaims', 'Territory', 'Annual.pct.driven', 'Total.miles.driven', 'Pct.drive.mon', 'Pct.drive.tue', 'Pct.drive.wed', 'Pct.drive.thr', 'Pct.drive.fri', 'Pct.drive.sat', 'Pct.drive.sun', 'Pct.drive.2hrs', 'Pct.drive.3hrs', 'Pct.drive.4hrs', 'Pct.drive.wkday', 'Pct.drive.wkend', 'Pct.drive.rush am', 'Pct.drive.rush pm', 'Avgdays.week', 'Accel.06miles', 'Accel.08miles', 'Accel.09miles', 'Accel.11miles', 'Accel.12miles', 'Accel.14miles', 'Brake.06miles', 'Brake.08miles', 'Brake.09miles', 'Brake.11miles', 'Brake.12miles', 'Brake.14miles', 'Left.turn.intensity08', 'Left.turn.intensity09', 'Left.turn.intensity10', 'Left.turn.intensity11', 'Left.turn.intensity12', 'Right.turn.intensity08', 'Right.turn.intensity09', 'Right.turn.intensity10', 'Right.turn.intensity11', 'Right.turn.intensity12', 'Insured.sex_Female', 'Insured.sex_Male', 'Marital_Married', 'Marital_Single', 'Car.use_Commercial', 'Car.use_Commute', 'Car.use_Farmer', 'Car.use_Private', 'Region_Rural', 'Region_Urban']\n",
            "\n",
            "Total number of columns after encoding: 56\n",
            "\n",
            "Final dataset shapes:\n",
            "Original features: (100000, 56)\n",
            "X_train_balanced: (155684, 56)\n",
            "X_test: (20000, 56)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Feature Engineering\n",
        "def create_aggregated_features(df):\n",
        "    \"\"\"Create aggregated features from existing ones\"\"\"\n",
        "\n",
        "    # Aggregate acceleration features\n",
        "    df['Agg_Accel'] = df[[\n",
        "        'Accel.06miles', 'Accel.08miles', 'Accel.09miles',\n",
        "        'Accel.11miles', 'Accel.12miles', 'Accel.14miles'\n",
        "    ]].mean(axis=1)\n",
        "\n",
        "    # Aggregate braking features\n",
        "    df['Agg_Brake'] = df[[\n",
        "        'Brake.06miles', 'Brake.08miles', 'Brake.09miles',\n",
        "        'Brake.11miles', 'Brake.12miles', 'Brake.14miles'\n",
        "    ]].mean(axis=1)\n",
        "\n",
        "    # Aggregate left turn features\n",
        "    df['Agg_Left_Turn'] = df[[\n",
        "        'Left.turn.intensity08', 'Left.turn.intensity09', 'Left.turn.intensity10',\n",
        "        'Left.turn.intensity11', 'Left.turn.intensity12'\n",
        "    ]].mean(axis=1)\n",
        "\n",
        "    # Aggregate right turn features\n",
        "    df['Agg_Right_Turn'] = df[[\n",
        "        'Right.turn.intensity08', 'Right.turn.intensity09', 'Right.turn.intensity10',\n",
        "        'Right.turn.intensity11', 'Right.turn.intensity12'\n",
        "    ]].mean(axis=1)\n",
        "\n",
        "    # Create overall harsh driving score\n",
        "    df['Harsh_Driving_Score'] = (\n",
        "        df['Agg_Accel'] + df['Agg_Brake'] +\n",
        "        df['Agg_Left_Turn'] + df['Agg_Right_Turn']\n",
        "    ) / 4\n",
        "\n",
        "    # Create rush hour driving ratio\n",
        "    df['Rush_Hour_Ratio'] = (\n",
        "        df['Pct.drive.rush am'] + df['Pct.drive.rush pm']\n",
        "    ) / df['Total.miles.driven']\n",
        "\n",
        "    return df\n",
        "\n",
        "# Standardization function\n",
        "def standardize_features(X_train, X_test):\n",
        "    \"\"\"Standardize numerical features\"\"\"\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Get numerical columns (exclude dummy variables)\n",
        "    numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "    # Fit and transform training data\n",
        "    X_train_scaled = X_train.copy()\n",
        "    X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "\n",
        "    # Transform test data\n",
        "    X_test_scaled = X_test.copy()\n",
        "    X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, scaler\n",
        "\n",
        "# Apply preprocessing pipeline\n",
        "def preprocess_data(X_train, X_test):\n",
        "    \"\"\"Complete preprocessing pipeline\"\"\"\n",
        "\n",
        "    # 1. Feature Engineering\n",
        "    print(\"Applying feature engineering...\")\n",
        "    X_train = create_aggregated_features(X_train)\n",
        "    X_test = create_aggregated_features(X_test)\n",
        "\n",
        "    # 2. Standardization\n",
        "    print(\"Standardizing features...\")\n",
        "    X_train_scaled, X_test_scaled, scaler = standardize_features(X_train, X_test)\n",
        "\n",
        "    # Print feature names and their shapes\n",
        "    print(\"\\nFinal feature set:\")\n",
        "    print(f\"Training set shape: {X_train_scaled.shape}\")\n",
        "    print(f\"Test set shape: {X_test_scaled.shape}\")\n",
        "    print(\"\\nFeatures included:\")\n",
        "    print(X_train_scaled.columns.tolist())\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, scaler\n",
        "\n",
        "# Apply preprocessing to our balanced dataset\n",
        "X_train_processed, X_test_processed, scaler = preprocess_data(X_train_balanced, X_test)\n",
        "\n",
        "# Print sample statistics to verify preprocessing\n",
        "print(\"\\nSample statistics after preprocessing:\")\n",
        "print(X_train_processed.describe().round(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq_dWqZy3zHr",
        "outputId": "a80f9f73-5980-4a4f-8ca7-b393a84ff6f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying feature engineering...\n",
            "Standardizing features...\n",
            "\n",
            "Final feature set:\n",
            "Training set shape: (155684, 62)\n",
            "Test set shape: (20000, 62)\n",
            "\n",
            "Features included:\n",
            "['Duration', 'Insured.age', 'Car.age', 'Credit.score', 'Annual.miles.drive', 'Years.noclaims', 'Territory', 'Annual.pct.driven', 'Total.miles.driven', 'Pct.drive.mon', 'Pct.drive.tue', 'Pct.drive.wed', 'Pct.drive.thr', 'Pct.drive.fri', 'Pct.drive.sat', 'Pct.drive.sun', 'Pct.drive.2hrs', 'Pct.drive.3hrs', 'Pct.drive.4hrs', 'Pct.drive.wkday', 'Pct.drive.wkend', 'Pct.drive.rush am', 'Pct.drive.rush pm', 'Avgdays.week', 'Accel.06miles', 'Accel.08miles', 'Accel.09miles', 'Accel.11miles', 'Accel.12miles', 'Accel.14miles', 'Brake.06miles', 'Brake.08miles', 'Brake.09miles', 'Brake.11miles', 'Brake.12miles', 'Brake.14miles', 'Left.turn.intensity08', 'Left.turn.intensity09', 'Left.turn.intensity10', 'Left.turn.intensity11', 'Left.turn.intensity12', 'Right.turn.intensity08', 'Right.turn.intensity09', 'Right.turn.intensity10', 'Right.turn.intensity11', 'Right.turn.intensity12', 'Insured.sex_Female', 'Insured.sex_Male', 'Marital_Married', 'Marital_Single', 'Car.use_Commercial', 'Car.use_Commute', 'Car.use_Farmer', 'Car.use_Private', 'Region_Rural', 'Region_Urban', 'Agg_Accel', 'Agg_Brake', 'Agg_Left_Turn', 'Agg_Right_Turn', 'Harsh_Driving_Score', 'Rush_Hour_Ratio']\n",
            "\n",
            "Sample statistics after preprocessing:\n",
            "        Duration  Insured.age    Car.age  Credit.score  Annual.miles.drive  \\\n",
            "count  155684.00    155684.00  155684.00     155684.00           155684.00   \n",
            "mean       -0.00         0.00       0.00          0.00               -0.00   \n",
            "std         1.00         1.00       1.00          1.00                1.00   \n",
            "min        -4.70        -2.19      -1.85         -4.21               -2.44   \n",
            "25%         0.40        -0.82      -0.78         -0.57               -0.84   \n",
            "50%         0.48        -0.06      -0.25          0.23               -0.04   \n",
            "75%         0.50         0.70       0.55          0.73                0.76   \n",
            "max         0.50         3.72       4.02          1.41               12.17   \n",
            "\n",
            "       Years.noclaims  Territory  Annual.pct.driven  Total.miles.driven  \\\n",
            "count       155684.00  155684.00          155684.00           155684.00   \n",
            "mean             0.00       0.00               0.00               -0.00   \n",
            "std              1.00       1.00               1.00                1.00   \n",
            "min             -1.65      -2.07              -2.09               -1.29   \n",
            "25%             -0.86      -0.89              -0.76               -0.77   \n",
            "50%             -0.12       0.25               0.09               -0.21   \n",
            "75%              0.74       0.84               0.98                0.55   \n",
            "max              3.54       1.56               1.25                7.87   \n",
            "\n",
            "       Pct.drive.mon  ...  Right.turn.intensity09  Right.turn.intensity10  \\\n",
            "count      155684.00  ...               155684.00               155684.00   \n",
            "mean            0.00  ...                    0.00                    0.00   \n",
            "std             1.00  ...                    1.00                    1.00   \n",
            "min            -4.12  ...                   -0.07                   -0.05   \n",
            "25%            -0.44  ...                   -0.06                   -0.05   \n",
            "50%            -0.03  ...                   -0.06                   -0.05   \n",
            "75%             0.39  ...                   -0.03                   -0.04   \n",
            "max            25.26  ...                   53.94                   56.68   \n",
            "\n",
            "       Right.turn.intensity11  Right.turn.intensity12  Agg_Accel  Agg_Brake  \\\n",
            "count               155684.00               155684.00  155684.00  155684.00   \n",
            "mean                    -0.00                    0.00      -0.00       0.00   \n",
            "std                      1.00                    1.00       1.00       1.00   \n",
            "min                     -0.04                   -0.04      -0.65      -1.10   \n",
            "25%                     -0.04                   -0.04      -0.49      -0.62   \n",
            "50%                     -0.04                   -0.04      -0.26      -0.25   \n",
            "75%                     -0.04                   -0.04       0.13       0.32   \n",
            "max                     60.77                   71.58      40.62      34.67   \n",
            "\n",
            "       Agg_Left_Turn  Agg_Right_Turn  Harsh_Driving_Score  Rush_Hour_Ratio  \n",
            "count      155684.00       155684.00            155684.00        155684.00  \n",
            "mean            0.00           -0.00                 0.00            -0.00  \n",
            "std             1.00            1.00                 1.00             1.00  \n",
            "min            -0.05           -0.06                -0.08            -0.02  \n",
            "25%            -0.05           -0.06                -0.08            -0.02  \n",
            "50%            -0.05           -0.05                -0.07            -0.02  \n",
            "75%            -0.04           -0.03                -0.05            -0.01  \n",
            "max            51.07           59.07                38.06           349.51  \n",
            "\n",
            "[8 rows x 52 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_P-eyX943Uc",
        "outputId": "b68cf6f6-a3f9-47c2-986c-6accd506b05a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.26.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.5.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (4.66.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch_tabnet) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch_tabnet\n",
            "Successfully installed pytorch_tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef, roc_curve\n",
        "\n",
        "# Deep Neural Network\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "\n",
        "# TabNet\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import torch\n",
        "\n",
        "# Ensure reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Assuming X and y are your features and target variables\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 1. Deep Neural Network\n",
        "def create_dnn_model(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_dim=input_dim),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "dnn_model = create_dnn_model(X_train.shape[1])\n",
        "dnn_history = dnn_model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "# 2. XGBoost\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    min_child_weight=1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. TabNet\n",
        "tabnet_model = TabNetClassifier(\n",
        "    n_d=16, n_a=16, n_steps=5,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    mask_type='entmax'\n",
        ")\n",
        "\n",
        "X_train_tab = X_train.astype(np.float32)\n",
        "y_train_tab = y_train.astype(np.int64)\n",
        "X_test_tab = X_test.astype(np.float32)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3hekMtJ4tIG",
        "outputId": "73e6a7e6-deb3-4377-a4e4-ae4b03746e6e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred_dnn = dnn_model.predict(X_test_scaled).ravel()\n",
        "y_pred_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Ensure TabNet returns probabilities\n",
        "y_pred_tabnet = tabnet_model.predict(X_test_tab)\n",
        "if hasattr(tabnet_model, 'predict_proba'):\n",
        "    y_pred_tabnet = tabnet_model.predict_proba(X_test_tab)[:, 1]\n",
        "\n",
        "# Ensemble predictions (simple average)\n",
        "y_pred_ensemble = (y_pred_dnn + y_pred_xgb + y_pred_tabnet) / 3\n",
        "\n",
        "# Calculate metrics for ensemble\n",
        "y_pred_ensemble_class = (y_pred_ensemble > 0.5).astype(int)\n",
        "metrics_ensemble = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_ensemble_class),\n",
        "    'precision': precision_score(y_test, y_pred_ensemble_class),\n",
        "    'recall': recall_score(y_test, y_pred_ensemble_class),\n",
        "    'f1': f1_score(y_test, y_pred_ensemble_class),\n",
        "    'auc': roc_auc_score(y_test, y_pred_ensemble),\n",
        "    'matthews_corr': matthews_corrcoef(y_test, y_pred_ensemble_class)\n",
        "}\n",
        "\n",
        "# Print ensemble metrics\n",
        "print(\"\\nEnsemble Model Performance Metrics:\")\n",
        "for metric, value in metrics_ensemble.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "for name, y_pred in [('DNN', y_pred_dnn), ('XGBoost', y_pred_xgb), ('TabNet', y_pred_tabnet), ('Ensemble', y_pred_ensemble)]:\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves Comparison')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "3U2l4oufiWkv",
        "outputId": "eca45228-cdd8-411d-e84e-703f36f96d0f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TabNetClassifier' object has no attribute 'network'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2d1e005b0a6a>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Ensure TabNet returns probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_pred_tabnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabnet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_proba'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my_pred_tabnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mPredictions\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mregression\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TabNetClassifier' object has no attribute 'network'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iowWuK9TpVtd",
        "outputId": "a822a1be-a620-40c1-e61a-5374ec7f6bad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.26.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.5.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import torch\n",
        "\n",
        "# Ensure reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# TabNet\n",
        "tabnet_model = TabNetClassifier(\n",
        "    n_d=16, n_a=16, n_steps=5,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    mask_type='entmax'\n",
        ")\n",
        "\n",
        "X_train_tab = X_train.astype(np.float32)\n",
        "y_train_tab = y_train.astype(np.int64)\n",
        "X_test_tab = X_test.astype(np.float32)\n",
        "\n",
        "tabnet_model.fit(\n",
        "    X_train_tab, y_train_tab,\n",
        "    eval_set=[(X_test_tab, y_test.astype(np.int64))],\n",
        "    max_epochs=50,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128\n",
        ")"
      ],
      "metadata": {
        "id": "u6bgEJRhqVv2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Make predictions\n",
        "y_pred_dnn = dnn_model.predict(X_test_scaled).ravel()\n",
        "y_pred_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "y_pred_tabnet = tabnet_model.predict_proba(X_test_tab)[:, 1]\n",
        "\n",
        "# Ensemble predictions (simple average)\n",
        "y_pred_ensemble = (y_pred_dnn + y_pred_xgb + y_pred_tabnet) / 3\n",
        "\n",
        "# Calculate metrics for ensemble\n",
        "y_pred_ensemble_class = (y_pred_ensemble > 0.5).astype(int)\n",
        "metrics_ensemble = {\n",
        "    'accuracy': accuracy_score(y_test, y_pred_ensemble_class),\n",
        "    'precision': precision_score(y_test, y_pred_ensemble_class),\n",
        "    'recall': recall_score(y_test, y_pred_ensemble_class),\n",
        "    'f1': f1_score(y_test, y_pred_ensemble_class),\n",
        "    'auc': roc_auc_score(y_test, y_pred_ensemble),\n",
        "    'matthews_corr': matthews_corrcoef(y_test, y_pred_ensemble_class)\n",
        "}\n",
        "\n",
        "# Print ensemble metrics\n",
        "print(\"\\nEnsemble Model Performance Metrics:\")\n",
        "for metric, value in metrics_ensemble.items():\n",
        "    print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "for name, y_pred in [('DNN', y_pred_dnn), ('XGBoost', y_pred_xgb), ('TabNet', y_pred_tabnet), ('Ensemble', y_pred_ensemble)]:\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves Comparison')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "AnxF1R8pqM5Q",
        "outputId": "13098a20-3cf9-4ebd-cca3-52828db59e6e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TabNetClassifier' object has no attribute 'network'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3e068ac3c7ba>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred_dnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred_tabnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Ensemble predictions (simple average)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/tab_model.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TabNetClassifier' object has no attribute 'network'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    y_pred_tabnet = tabnet_model.predict_proba(X_test_tab)[:, 1]\n",
        "except AttributeError as e:\n",
        "    print(f\"Error predicting with TabNet: {e}\")\n",
        "    y_pred_tabnet = np.zeros(len(y_test))  # Fallback to zeros if prediction fails"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FdcRwZSqlLx",
        "outputId": "ef79e0f7-dd86-46b3-a0b9-197472c3beae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error predicting with TabNet: 'TabNetClassifier' object has no attribute 'network'\n"
          ]
        }
      ]
    }
  ]
}