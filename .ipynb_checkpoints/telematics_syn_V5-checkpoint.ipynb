{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjIAdzQlOTu5wNdCZ7RJZq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Artificial_Intelligence_Learning/blob/master/telematics_syn_V5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxre3ydMU1vF",
        "outputId": "aa2a4351-3a6b-4418-860e-393f8019d225"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify file path\n",
        "file_path = '/content/drive/My Drive/Dissertation/telematics_syn.csv'\n",
        "\n",
        "# Import pandas (assuming you want to use it to read the CSV)\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.shape)  # Should print (100000, 52)\n",
        "\n",
        "print(df.head())  # Example: print the first few rows of the dataframe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTxzMntBVCZ_",
        "outputId": "73488701-16a6-4173-cbb4-fa4fb945bb39"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(100000, 52)\n",
            "   Duration  Insured.age Insured.sex  Car.age  Marital  Car.use  Credit.score  \\\n",
            "0       366           45        Male       -1  Married  Commute         609.0   \n",
            "1       182           44      Female        3  Married  Commute         575.0   \n",
            "2       184           48      Female        6  Married  Commute         847.0   \n",
            "3       183           71        Male        6  Married  Private         842.0   \n",
            "4       183           84        Male       10  Married  Private         856.0   \n",
            "\n",
            "  Region  Annual.miles.drive  Years.noclaims  ...  Left.turn.intensity10  \\\n",
            "0  Urban             6213.71              25  ...                    1.0   \n",
            "1  Urban            12427.42              20  ...                   58.0   \n",
            "2  Urban            12427.42              14  ...                    0.0   \n",
            "3  Urban             6213.71              43  ...                    0.0   \n",
            "4  Urban             6213.71              65  ...                    2.0   \n",
            "\n",
            "   Left.turn.intensity11  Left.turn.intensity12  Right.turn.intensity08  \\\n",
            "0                    0.0                    0.0                     3.0   \n",
            "1                   24.0                   11.0                  1099.0   \n",
            "2                    0.0                    0.0                     0.0   \n",
            "3                    0.0                    0.0                     0.0   \n",
            "4                    0.0                    0.0                   325.0   \n",
            "\n",
            "   Right.turn.intensity09  Right.turn.intensity10  Right.turn.intensity11  \\\n",
            "0                     1.0                     0.0                     0.0   \n",
            "1                   615.0                   219.0                   101.0   \n",
            "2                     0.0                     0.0                     0.0   \n",
            "3                     0.0                     0.0                     0.0   \n",
            "4                   111.0                    18.0                     4.0   \n",
            "\n",
            "   Right.turn.intensity12  NB_Claim    AMT_Claim  \n",
            "0                     0.0         1  5100.171753  \n",
            "1                    40.0         1   883.554840  \n",
            "2                     0.0         0     0.000000  \n",
            "3                     0.0         0     0.000000  \n",
            "4                     2.0         0     0.000000  \n",
            "\n",
            "[5 rows x 52 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#step 2"
      ],
      "metadata": {
        "id": "Ok2DoiD5fsPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pre1"
      ],
      "metadata": {
        "id": "nt77pX65f_ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding categorical columns using one-hot encoding\n",
        "categorical_cols = ['Marital', 'Insured.sex', 'Car.use', 'Region', 'Territory']\n",
        "df = pd.get_dummies(df, columns=categorical_cols)\n",
        "\n",
        "# Creating the ClaimYN variable\n",
        "df['ClaimYN'] = df['NB_Claim'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# Saving the preprocessed data to a new file\n",
        "preprocessed_file_path = '/content/drive/My Drive/pre_telematics_syn.csv'\n",
        "df.to_csv(preprocessed_file_path, index=False)\n",
        "print(df.shape)  # Should print (100000, number of columns after encoding)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4liZny1fp8V",
        "outputId": "f9830bc9-9df1-4ad3-8813-db21be7490b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 113)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pre2"
      ],
      "metadata": {
        "id": "ZBcFKlvbgE2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Feature columns (excluding response columns)\n",
        "feature_cols = [col for col in df.columns if col not in ['NB_Claim', 'AMT_Claim', 'ClaimYN']]\n",
        "\n",
        "# Applying StandardScaler and MinMaxScaler\n",
        "scaler = StandardScaler()\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
        "df[feature_cols] = minmax_scaler.fit_transform(df[feature_cols])\n",
        "\n",
        "# Save the preprocessed data to a new file\n",
        "preprocessed_file_path_scaled = '/content/drive/My Drive/pre_telematics_syn_scaled.csv'\n",
        "df.to_csv(preprocessed_file_path_scaled, index=False)\n",
        "print(df.shape)  # Should print (100000, number of columns after scaling and normalization)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr_HBUAggGn8",
        "outputId": "c49fa0f0-6cc7-4148-c25c-8398541cc439"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 113)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pre3"
      ],
      "metadata": {
        "id": "DfnrpjvvgLoB"
      }
    },
    {
      "source": [
        "# Advanced feature engineering steps, if any\n",
        "# For example, aggregating harsh driving events:\n",
        "# Check if the columns exist before using them\n",
        "if all(col in df.columns for col in ['Accel.xx.miles', 'Brake.xx.miles', 'Left.turn.intensityxx', 'Right.turn.intensityxx']):\n",
        "    df['HarshDriving'] = df['Accel.xx.miles'] + df['Brake.xx.miles'] + df['Left.turn.intensityxx'] + df['Right.turn.intensityxx']\n",
        "else:\n",
        "    print(\"Warning: One or more columns required for 'HarshDriving' calculation are missing.\")\n",
        "\n",
        "# Save the fully preprocessed data to a new file\n",
        "preprocessed_file_path_final = '/content/drive/My Drive/pre_telematics_syn_advanced.csv'\n",
        "df.to_csv(preprocessed_file_path_final, index=False)\n",
        "print(df.shape)  # Should print (100000, number of columns after feature engineering)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weJCxT8lgaIQ",
        "outputId": "f235722d-8b90-40df-d7d7-86e542f540a9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: One or more columns required for 'HarshDriving' calculation are missing.\n",
            "(100000, 113)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the response and feature columns\n",
        "response_cols = ['NB_Claim', 'AMT_Claim', 'ClaimYN']\n",
        "feature_cols = [col for col in df.columns if col not in response_cols]\n",
        "\n",
        "# Split into 80% train and 20% test\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further split train into train and validation\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(train_df.shape, val_df.shape, test_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pnc1tLTkdh3c",
        "outputId": "5c25a46f-3c39-4fae-82b5-107647d1ea9f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64000, 113) (16000, 113) (20000, 113)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIiUK8D5dj2p",
        "outputId": "103c8155-635e-45a7-f60e-dc6b92d11daf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.25.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->pytorch-tabnet) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the library\n",
        "!pip install pytorch-tabnet\n",
        "\n",
        "# Import required libraries\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Prepare the data for TabNet\n",
        "X_train = train_df[feature_cols].values\n",
        "y_train = train_df['ClaimYN'].values\n",
        "X_val = val_df[feature_cols].values\n",
        "y_val = val_df['ClaimYN'].values\n",
        "X_test = test_df[feature_cols].values\n",
        "y_test = test_df['ClaimYN'].values\n",
        "\n",
        "# Create and train the TabNet model\n",
        "clf = TabNetClassifier()\n",
        "\n",
        "clf.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    eval_name=['train', 'val'],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=50,\n",
        "    patience=10,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    weights=1,\n",
        "    drop_last=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsV9ZhfSgtBU",
        "outputId": "20d27411-b49a-475f-de90-ed1fb9f3801c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.25.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->pytorch-tabnet) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.64125 | train_accuracy: 0.19758 | val_accuracy: 0.20319 |  0:00:08s\n",
            "epoch 1  | loss: 0.57605 | train_accuracy: 0.13955 | val_accuracy: 0.14269 |  0:00:18s\n",
            "epoch 2  | loss: 0.56285 | train_accuracy: 0.22433 | val_accuracy: 0.22725 |  0:00:27s\n",
            "epoch 3  | loss: 0.55817 | train_accuracy: 0.3637  | val_accuracy: 0.36531 |  0:00:36s\n",
            "epoch 4  | loss: 0.55079 | train_accuracy: 0.57991 | val_accuracy: 0.57969 |  0:00:45s\n",
            "epoch 5  | loss: 0.54498 | train_accuracy: 0.52409 | val_accuracy: 0.525   |  0:00:55s\n",
            "epoch 6  | loss: 0.5384  | train_accuracy: 0.62292 | val_accuracy: 0.624   |  0:01:03s\n",
            "epoch 7  | loss: 0.53232 | train_accuracy: 0.63564 | val_accuracy: 0.63525 |  0:01:13s\n",
            "epoch 8  | loss: 0.53003 | train_accuracy: 0.63997 | val_accuracy: 0.63694 |  0:01:23s\n",
            "epoch 9  | loss: 0.52534 | train_accuracy: 0.67819 | val_accuracy: 0.67494 |  0:01:31s\n",
            "epoch 10 | loss: 0.52049 | train_accuracy: 0.67628 | val_accuracy: 0.67094 |  0:01:41s\n",
            "epoch 11 | loss: 0.51506 | train_accuracy: 0.70188 | val_accuracy: 0.70025 |  0:01:50s\n",
            "epoch 12 | loss: 0.5142  | train_accuracy: 0.66061 | val_accuracy: 0.65481 |  0:01:58s\n",
            "epoch 13 | loss: 0.51686 | train_accuracy: 0.65788 | val_accuracy: 0.6565  |  0:02:08s\n",
            "epoch 14 | loss: 0.52363 | train_accuracy: 0.67878 | val_accuracy: 0.67662 |  0:02:18s\n",
            "epoch 15 | loss: 0.5072  | train_accuracy: 0.67895 | val_accuracy: 0.67194 |  0:02:26s\n",
            "epoch 16 | loss: 0.50394 | train_accuracy: 0.65642 | val_accuracy: 0.64719 |  0:02:36s\n",
            "epoch 17 | loss: 0.50038 | train_accuracy: 0.69506 | val_accuracy: 0.69244 |  0:02:45s\n",
            "epoch 18 | loss: 0.50654 | train_accuracy: 0.68081 | val_accuracy: 0.67738 |  0:02:54s\n",
            "epoch 19 | loss: 0.50118 | train_accuracy: 0.72308 | val_accuracy: 0.71931 |  0:03:04s\n",
            "epoch 20 | loss: 0.49038 | train_accuracy: 0.67264 | val_accuracy: 0.66644 |  0:03:13s\n",
            "epoch 21 | loss: 0.48418 | train_accuracy: 0.70406 | val_accuracy: 0.69669 |  0:03:22s\n",
            "epoch 22 | loss: 0.47234 | train_accuracy: 0.6938  | val_accuracy: 0.68756 |  0:03:31s\n",
            "epoch 23 | loss: 0.47083 | train_accuracy: 0.73272 | val_accuracy: 0.72406 |  0:03:41s\n",
            "epoch 24 | loss: 0.46314 | train_accuracy: 0.75612 | val_accuracy: 0.74712 |  0:03:49s\n",
            "epoch 25 | loss: 0.46512 | train_accuracy: 0.72127 | val_accuracy: 0.71075 |  0:03:59s\n",
            "epoch 26 | loss: 0.45999 | train_accuracy: 0.70141 | val_accuracy: 0.6915  |  0:04:08s\n",
            "epoch 27 | loss: 0.44355 | train_accuracy: 0.75623 | val_accuracy: 0.74356 |  0:04:17s\n",
            "epoch 28 | loss: 0.4361  | train_accuracy: 0.75797 | val_accuracy: 0.74856 |  0:04:27s\n",
            "epoch 29 | loss: 0.4333  | train_accuracy: 0.74797 | val_accuracy: 0.74069 |  0:04:36s\n",
            "epoch 30 | loss: 0.4385  | train_accuracy: 0.74477 | val_accuracy: 0.72894 |  0:04:45s\n",
            "epoch 31 | loss: 0.42559 | train_accuracy: 0.7602  | val_accuracy: 0.74688 |  0:04:55s\n",
            "epoch 32 | loss: 0.41916 | train_accuracy: 0.76166 | val_accuracy: 0.75019 |  0:05:04s\n",
            "epoch 33 | loss: 0.40875 | train_accuracy: 0.75847 | val_accuracy: 0.74762 |  0:05:13s\n",
            "epoch 34 | loss: 0.41076 | train_accuracy: 0.75633 | val_accuracy: 0.73869 |  0:05:23s\n",
            "epoch 35 | loss: 0.40138 | train_accuracy: 0.78123 | val_accuracy: 0.76331 |  0:05:32s\n",
            "epoch 36 | loss: 0.40295 | train_accuracy: 0.75889 | val_accuracy: 0.74388 |  0:05:41s\n",
            "epoch 37 | loss: 0.4033  | train_accuracy: 0.76306 | val_accuracy: 0.74719 |  0:05:51s\n",
            "epoch 38 | loss: 0.39102 | train_accuracy: 0.76992 | val_accuracy: 0.75381 |  0:06:00s\n",
            "epoch 39 | loss: 0.39691 | train_accuracy: 0.76414 | val_accuracy: 0.74581 |  0:06:09s\n",
            "epoch 40 | loss: 0.38429 | train_accuracy: 0.78936 | val_accuracy: 0.76838 |  0:06:19s\n",
            "epoch 41 | loss: 0.3738  | train_accuracy: 0.79912 | val_accuracy: 0.77825 |  0:06:29s\n",
            "epoch 42 | loss: 0.3769  | train_accuracy: 0.79811 | val_accuracy: 0.77938 |  0:06:39s\n",
            "epoch 43 | loss: 0.36951 | train_accuracy: 0.79217 | val_accuracy: 0.77012 |  0:06:49s\n",
            "epoch 44 | loss: 0.37047 | train_accuracy: 0.79434 | val_accuracy: 0.77625 |  0:06:58s\n",
            "epoch 45 | loss: 0.36942 | train_accuracy: 0.78239 | val_accuracy: 0.76288 |  0:07:07s\n",
            "epoch 46 | loss: 0.35507 | train_accuracy: 0.8082  | val_accuracy: 0.78419 |  0:07:17s\n",
            "epoch 47 | loss: 0.35537 | train_accuracy: 0.79478 | val_accuracy: 0.76731 |  0:07:26s\n",
            "epoch 48 | loss: 0.36304 | train_accuracy: 0.79503 | val_accuracy: 0.771   |  0:07:35s\n",
            "epoch 49 | loss: 0.341   | train_accuracy: 0.80708 | val_accuracy: 0.77856 |  0:07:45s\n",
            "Stop training because you reached max_epochs = 50 with best_epoch = 46 and best_val_accuracy = 0.78419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    }
  ]
}