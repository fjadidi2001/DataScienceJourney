

Preprocessing a dataset
پیش پردازش یک مجموعه داده گامی مهم در تجزیه و تحلیل داده ها و پایپ لاین یادگیری ماشین است. این شامل تبدیل داده های خام به قالبی است که برای مدل سازی مناسب تر است. هدف از پیش پردازش این است که اطمینان حاصل شود که داده ها تمیز، منظم و در قالبی هستند که به راحتی توسط الگوریتم های یادگیری ماشین تفسیر شوند. در اینجا چند مرحله متداول پیش پردازش آورده شده است:

1. **Data Cleaning**: این شامل رسیدگی به مقادیر از دست رفته، حذف موارد تکراری و تصحیح هر گونه خطا در داده ها است. مقادیر گمشده را می‌توان با میانگین، میانه، حالت یا استراتژی‌های دیگر بسته به ماهیت داده‌ها نسبت داد.

2. **Data Transformation**: شامل نرمال سازی و استانداردسازی می شود، که تکنیک هایی برای مقیاس بندی ویژگی ها به گونه ای هستند که به طور مساوی در مدل مشارکت داشته باشند. نزمال سازی داده ها را بین 0 و 1 مقیاس می کند، در حالی که استانداردسازی داده ها را به میانگین 0 و انحراف استاندارد 1 تبدیل می کند.

3. **Encoding Categorical Data**: مدل های یادگیری ماشین معمولاً به ورودی عددی نیاز دارند. متغیرهای طبقه‌بندی باید با استفاده از تکنیک‌هایی مانند one-hot encoding or label encoding به شکل عددی تبدیل شوند.

4. ** Handling Imbalanced Data **: اگر مجموعه داده نامتعادل باشد، به این معنی که تفاوت قابل توجهی در تعداد نمونه های متعلق به هر کلاس وجود دارد، تکنیک هایی مانند نمونه برداری بیش از حد از کلاس اقلیت، نمونه برداری کمتر از کلاس اکثریت، یا استفاده از الگوریتم هایی که طراحی شده اند. برای رسیدگی به داده های نامتعادل می توان از آن استفاده کرد.

5. **Feature Selection**: این مرحله شامل انتخاب مرتبط ترین ویژگی ها برای مدل برای بهبود عملکرد و کاهش overfitting است.
تکنیک‌ها شامل روش‌های  filter methods, wrapper methods, embedded methods است.

6. **Dimensionality Reduction**: هنگامی که مجموعه داده دارای تعداد زیادی ویژگی است، می توان از تکنیک های کاهش ابعاد مانند تجزیه و تحلیل مؤلفه اصلی (PCA) برای کاهش تعداد ویژگی ها با ایجاد ویژگی های جدید استفاده کرد که ترکیبی خطی از ویژگی های اصلی هستند. .

7. **Data Augmentation**: در مواردی که مجموعه داده کوچک است، می توان از تقویت داده ها برای افزایش مصنوعی اندازه مجموعه داده با ایجاد نسخه های اصلاح شده از داده های موجود استفاده کرد.

8. **Feature Scaling**: این امر به ویژه برای الگوریتم‌هایی که فاصله‌ها را محاسبه می‌کنند یا از شیب نزول استفاده می‌کنند مهم است، زیرا ویژگی‌هایی با مقیاس‌های بزرگ‌تر می‌توانند بر فرآیند یادگیری تسلط داشته باشند.

9. **Splitting Data**: قبل از آموزش مدل، مجموعه داده معمولاً به مجموعه های آموزشی، اعتبار سنجی و آزمایش تقسیم می شود تا اطمینان حاصل شود که مدل بر روی داده های دیده نشده ارزیابی می شود.

10. **Data Formatting**: اطمینان از اینکه داده‌ها در قالب صحیح الگوریتم یادگیری ماشین هستند، مانند تبدیل متن به مقادیر عددی یا تغییر شکل داده‌ها برای مطابقت با الزامات ورودی مدل.

