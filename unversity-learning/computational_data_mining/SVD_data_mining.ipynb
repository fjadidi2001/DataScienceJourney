{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD/xVgCOfJabXxpaV+0tgj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Artificial_Intelligence_Learning/blob/master/SVD_data_mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy scipy scikit-learn matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qOu6nBHheoR",
        "outputId": "360cdea0-21d6-4a12-a9ef-d73e34474d37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "python project:\n",
        "Classiﬁcation of Handwritten Digits\n",
        "We will treat the digits in three diﬀerent but equivalent formats:\n",
        "1. As 16 × 16 gray scale images\n",
        "2. As functions of two variables, s = s(x, y)\n",
        "3. As vectors in R256 .\n",
        "In the classiﬁcation of an unknown digit we need to compute the distance\n",
        "to known digits. Diﬀerent distance measures can be used, and perhaps the most\n",
        "natural one to use is the Euclidean distance: stack the columns of the image in a vector and identify each digit as a vector in R^256 . Then deﬁne the distance function (x, y) =|| x − y||2\n",
        "An alternative distance function is the cosine between two vectors.\n",
        "Given a set of manually classiﬁed digits (the training set), classify a set\n",
        "of unknown digits (the test set)\n",
        "the project have continue first understand this"
      ],
      "metadata": {
        "id": "p9SVDX37EeX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation: You'll need a dataset of handwritten digits. This could be the MNIST dataset, which is a large database of handwritten digits that is commonly used for training various image processing systems. You'll need to preprocess the data to convert it into the three different representations you mentioned.\n",
        "\n",
        "Image Representation: For the 16x16 gray scale images, you can use libraries like OpenCV or PIL to read and manipulate the images.\n",
        "\n",
        "Function Representation: For the function representation, you'll need to convert the image into a function. This could be as simple as a 2D array of pixel values, or you could use more complex functions if you want.\n",
        "\n",
        "Vector Representation: For the vector representation, you'll need to flatten the image into a 1D array of pixel values.\n",
        "\n",
        "Distance Measures: Once you have your representations, you can compute the distances between them using the Euclidean and cosine distance measures.\n",
        "\n",
        "Classification: Use the training set to classify the unknown digits in the test set. This could be done using a simple nearest neighbor algorithm, where you find the training example that is closest to the test example in the feature space."
      ],
      "metadata": {
        "id": "zQp0GHl8E6Vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.spatial import distance\n",
        "\n",
        "# Load MNIST data\n",
        "mnist = fetch_openml('mnist_784')\n",
        "X, y = mnist.data, mnist.target\n",
        "\n",
        "# Select a subset of the data\n",
        "subset_indices = np.random.choice(np.where((y == '0') | (y == '1') | (y == '2') | (y == '3') | (y == '4') | (y == '5') | (y == '6') | (y == '7') | (y == '8') | (y == '9'))[0], size=1707, replace=False)\n",
        "X_subset, y_subset = X[subset_indices], y[subset_indices]\n",
        "\n",
        "# Split the subset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=2007, stratify=y_subset)\n",
        "\n",
        "# Implement the classification function\n",
        "def classify(x_test, x_train, y_train, distance_func):\n",
        "    y_pred = []\n",
        "    for test_point in x_test:\n",
        "        distances = [distance_func(test_point, train_point) for train_point in x_train]\n",
        "        min_index = np.argmin(distances)\n",
        "        y_pred.append(y_train[min_index])\n",
        "    return np.array(y_pred)\n",
        "\n",
        "# Classify the test set using Euclidean distance\n",
        "y_pred_euclidean = classify(X_test, X_train, y_train, distance.euclidean)\n",
        "\n",
        "# Classify the test set using cosine distance\n",
        "y_pred_cosine = classify(X_test, X_train, y_train, distance.cosine)\n",
        "\n",
        "# Evaluate the performance\n",
        "accuracy_euclidean = np.sum(y_pred_euclidean == y_test) / len(y_test)\n",
        "accuracy_cosine = np.sum(y_pred_cosine == y_test) / len(y_test)\n",
        "\n",
        "print(f'Accuracy with Euclidean distance: {accuracy_euclidean}')\n",
        "print(f'Accuracy with Cosine distance: {accuracy_cosine}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "aRpf62MuFW2e",
        "outputId": "9dde1ff1-5a3e-4526-b6cc-cace51886d7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index([66032,  8427, 62760, 67633, 64667,  6263, 46939, 44947, 45378, 37985,\\n       ...\\n       12922, 51603, 69872, 12024, 52578, 47708, 36792, 47149,  7657, 64277],\\n      dtype='int64', length=1707)] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9d1c9ed1f11f>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Select a subset of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msubset_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'4'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'5'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'6'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'7'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'9'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1707\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Split the subset into training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3767\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3769\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5875\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5937\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5938\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5940\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([66032,  8427, 62760, 67633, 64667,  6263, 46939, 44947, 45378, 37985,\\n       ...\\n       12922, 51603, 69872, 12024, 52578, 47708, 36792, 47149,  7657, 64277],\\n      dtype='int64', length=1707)] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "m0KhflFQHDqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Preparation:\n",
        "\n",
        "Load the MNIST dataset using a library like tensorflow.keras.datasets or sklearn.datasets.\n",
        "\n",
        "Select a subset of the data that includes 1707 digits equally distributed between 0 and 9.\n",
        "\n",
        "Split the subset into a training set and a test set.\n",
        "\n",
        "2. Image Representation:\n",
        "\n",
        "Reshape the images to 16x16 pixels.\n",
        "\n",
        "Normalize the pixel values to be between 0 and 1.\n",
        "\n",
        "3. Function Representation:\n",
        "\n",
        "Convert the images to 2D functions by treating the pixel values as a function of two variables (x, y).\n",
        "\n",
        "4. Vector Representation:\n",
        "\n",
        "Flatten the images to 1D vectors.\n",
        "\n",
        "5. Distance Measures:\n",
        "\n",
        "Implement the Euclidean distance function for vectors.\n",
        "\n",
        "Implement the cosine distance function for vectors.\n",
        "\n",
        "6. Classification:\n",
        "\n",
        "Implement a nearest neighbor algorithm to classify the test set based on the training set.\n",
        "\n",
        "Use the Euclidean and cosine distance measures to compare the test vectors with the training vectors.\n",
        "\n",
        "7. Evaluation:\n",
        "\n",
        "Compare the predicted labels with the actual labels to evaluate the performance of the classifier."
      ],
      "metadata": {
        "id": "q8ZNEFcAFmKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " If we consider the training set digits as vectors or points, and we're using the Euclidean distance, then it's reasonable to assume that all digits of one kind form a cluster of points in a 256-dimensional vector space. The ideal situation is that these clusters are well separated, meaning that it's easy to distinguish between different digits based on their vectors.\n",
        "\n",
        "The separation between the clusters would depend on the quality of the training data. If the training digits are well written and clear, the clusters should be well separated, making it easier to classify new, unseen digits. Conversely, if the training digits are messy, blurry, or have a lot of noise, the clusters might not be well separated, making it harder to classify new digits.\n",
        "\n",
        "This is a classic example of the curse of dimensionality in machine learning. In high-dimensional spaces, all data points tend to be far apart, regardless of their actual distance. This can make it difficult to find meaningful patterns and clusters. However, with enough training data and appropriate preprocessing, it's often possible to overcome this issue."
      ],
      "metadata": {
        "id": "WDSCO6PvGn1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load MNIST data\n",
        "mnist = fetch_openml('mnist_784')\n",
        "X, y = mnist.data, mnist.target\n",
        "\n",
        "# Select a subset of the data\n",
        "subset_indices = np.random.choice(np.where((y == '0') | (y == '1') | (y == '2') | (y == '3') | (y == '4') | (y == '5') | (y == '6') | (y == '7') | (y == '8') | (y == '9'))[0], size=1707, replace=False)\n",
        "X_subset, y_subset = X[subset_indices], y[subset_indices]\n",
        "\n",
        "# Split the subset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=2007, stratify=y_subset)\n",
        "\n",
        "# Implement the nearest neighbor classifier\n",
        "def nearest_neighbor_classifier(x_test, x_train, y_train):\n",
        "    y_pred = []\n",
        "    for test_point in x_test:\n",
        "        distances = np.linalg.norm(x_train - test_point, axis=1)\n",
        "        min_index = np.argmin(distances)\n",
        "        y_pred.append(y_train[min_index])\n",
        "    return np.array(y_pred)\n",
        "\n",
        "# Classify the test set\n",
        "y_pred = nearest_neighbor_classifier(X_test, X_train, y_train)\n",
        "\n",
        "# Evaluate the performance\n",
        "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "Qx_M-MCLGgW2",
        "outputId": "c481125f-71c3-4f26-81a4-7d34401b237e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index([ 7437, 52637, 31930, 64795, 55392, 23838, 19708, 21960, 29045, 48208,\\n       ...\\n       35627, 28487, 31522, 10752, 37663, 24980, 11136, 60318, 19276, 25351],\\n      dtype='int64', length=1707)] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-02e020a9b0c6>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Select a subset of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msubset_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'4'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'5'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'6'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'7'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'9'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1707\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Split the subset into training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3767\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3769\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5875\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5877\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5879\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5937\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5938\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5940\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index([ 7437, 52637, 31930, 64795, 55392, 23838, 19708, 21960, 29045, 48208,\\n       ...\\n       35627, 28487, 31522, 10752, 37663, 24980, 11136, 60318, 19276, 25351],\\n      dtype='int64', length=1707)] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the column names to verify they exist\n",
        "print(df.columns)\n",
        "\n",
        "# If the column names are valid, you can access the DataFrame like this\n",
        "# Replace 'column_name' with the actual column name you want to access\n",
        "df['column_name']\n",
        "\n",
        "# If you have a list of column names and you want to access multiple columns\n",
        "column_list = ['column1', 'column2', 'column3']  # Replace with your actual column names\n",
        "df[column_list]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "PHkvkXONHHZ2",
        "outputId": "ef020bb3-3c73-457d-b513-bdba0af5f620"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5023cc81d9e2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the column names to verify they exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# If the column names are valid, you can access the DataFrame like this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Replace 'column_name' with the actual column name you want to access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming you have a list of feature vectors for known digits (train_features)\n",
        "# and their corresponding labels (train_labels)\n",
        "\n",
        "def euclidean_distance(a, b):\n",
        "    return np\\.linalg\\.norm(a - b)\n",
        "\n",
        "def classify_digit(unknown_feature_vector, train_features, train_labels):\n",
        "    min_distance = float('inf')\n",
        "    predicted_label = None\n",
        "\n",
        "    for i, known_feature_vector in enumerate(train_features):\n",
        "        distance = euclidean_distance(unknown_feature_vector, known_feature_vector)\n",
        "        if distance < min_distance:\n",
        "            min_distance = distance\n",
        "            predicted_label = train_labels[i]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Example usage:\n",
        "unknown_feature_vector = np\\.array([0\\.1, 0\\.2, \\.\\.\\., 0\\.8])  # Replace with actual feature vector\n",
        "predicted_digit = classify_digit(unknown_feature_vector, train_features, train_labels)\n",
        "print(f\"Predicted digit: {predicted_digit}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "JSBTZqYzDJwR",
        "outputId": "1886f9b0-4f77-48c2-bbe1-fefde78d1559"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (<ipython-input-1-a505f3fa1589>, line 7)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a505f3fa1589>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    return np\\.linalg\\.norm(a - b)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import svd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist[\"data\"], mnist[\"target\"].astype(np.int)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Function to compute the SVD bases for each digit class\n",
        "def compute_svd_bases(X, y):\n",
        "    digit_classes = np.unique(y)\n",
        "    svd_bases = {}\n",
        "    for digit_class in digit_classes:\n",
        "        # Select the instances of the current digit class\n",
        "        class_indices = np.where(y == digit_class)[0]\n",
        "        class_data = X[class_indices]\n",
        "\n",
        "        # Compute the SVD for the class data\n",
        "        U, S, Vt = svd(class_data, full_matrices=False)\n",
        "        svd_bases[digit_class] = (U, S, Vt)\n",
        "    return svd_bases\n",
        "\n",
        "# Function to classify a test digit based on the residuals in the SVD bases\n",
        "def classify_digit(test_digit, svd_bases):\n",
        "    residuals = {}\n",
        "    for digit_class, (U, S, Vt) in svd_bases.items():\n",
        "        # Compute the residual for the current SVD basis\n",
        "        residual = np.linalg.norm(test_digit - U @ (U.T @ test_digit), ord=2)\n",
        "        residuals[digit_class] = residual\n",
        "\n",
        "    # Classify the test digit based on the smallest residual\n",
        "    classified_class = min(residuals, key=residuals.get)\n",
        "    return classified_class, residuals\n",
        "\n",
        "# Compute the SVD bases for each digit class in the training set\n",
        "svd_bases = compute_svd_bases(X_train_scaled, y_train)\n",
        "\n",
        "# Classify a test digit\n",
        "test_index = 0  # Index of the test digit to classify\n",
        "test_digit = X_test_scaled[test_index]\n",
        "classified_class, residuals = classify_digit(test_digit, svd_bases)\n",
        "\n",
        "# Print the classification result\n",
        "print(f\"The digit at index {test_index} is classified as {classified_class} with residuals: {residuals}\")\n",
        "\n",
        "# Visualize the test digit\n",
        "import matplotlib.pyplot as plt\n",
        "test_image = X_test[test_index].reshape(28, 28)\n",
        "plt.imshow(test_image, cmap=\"binary\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"True label: {y_test[test_index]}, Predicted: {classified_class}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "XVkJmjw6ho8k",
        "outputId": "302bc014-f8f1-4a48-a3f8-e73dd93422a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1832d59de8bc>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the MNIST dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist_784'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Split the dataset into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'testing'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import svd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist[\"data\"], mnist[\"target\"].astype(int)  # Use `int` directly\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Function to compute the SVD bases for each digit class\n",
        "def compute_svd_bases(X, y):\n",
        "    digit_classes = np.unique(y)\n",
        "    svd_bases = {}\n",
        "    for digit_class in digit_classes:\n",
        "        # Select the instances of the current digit class\n",
        "        class_indices = np.where(y == digit_class)[0]\n",
        "        class_data = X[class_indices]\n",
        "\n",
        "        # Compute the SVD for the class data\n",
        "        U, S, Vt = svd(class_data, full_matrices=False)\n",
        "        svd_bases[digit_class] = (U, S, Vt)\n",
        "    return svd_bases\n",
        "\n",
        "# # Function to classify a test digit based on the residuals in the SVD bases\n",
        "# def classify_digit(test_digit, svd_bases):\n",
        "#     residuals = {}\n",
        "#     for digit_class, (U, S, Vt) in svd_bases.items():\n",
        "#         # Compute the residual for the current SVD basis\n",
        "#         residual = np.linalg.norm(test_digit - U @ (U.T @ test_digit), ord=2)\n",
        "#         residuals[digit_class] = residual\n",
        "\n",
        "#     # Classify the test digit based on the smallest residual\n",
        "#     classified_class = min(residuals, key=residuals.get)\n",
        "#     return classified_class, residuals\n",
        "# Function to classify a test digit based on the residuals in the SVD bases\n",
        "def classify_digit(test_digit, svd_bases):\n",
        "    residuals = {}\n",
        "    for digit_class, (U, S, Vt) in svd_bases.items():\n",
        "        # Reshape the test digit to have the same number of columns as U\n",
        "        test_digit_reshaped = test_digit.reshape(-1, U.shape[0])\n",
        "\n",
        "        # Compute the residual for the current SVD basis\n",
        "        residual = np.linalg.norm(test_digit_reshaped - np.dot(U, np.dot(U.T, test_digit_reshaped)), ord=2)\n",
        "        residuals[digit_class] = residual\n",
        "\n",
        "    # Classify the test digit based on the smallest residual\n",
        "    classified_class = min(residuals, key=residuals.get)\n",
        "    return classified_class, residuals\n",
        "# Compute the SVD bases for each digit class in the training set\n",
        "svd_bases = compute_svd_bases(X_train_scaled, y_train)\n",
        "\n",
        "# Classify a test digit\n",
        "test_index = 0  # Index of the test digit to classify\n",
        "test_digit = X_test_scaled[test_index]\n",
        "classified_class, residuals = classify_digit(test_digit, svd_bases)\n",
        "\n",
        "# Print the classification result\n",
        "print(f\"The digit at index {test_index} is classified as {classified_class} with residuals: {residuals}\")\n",
        "\n",
        "# Visualize the test digit\n",
        "test_image = X_test[test_index].reshape(28, 28)\n",
        "plt.imshow(test_image, cmap=\"binary\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"True label: {y_test[test_index]}, Predicted: {classified_class}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "wcFt9Ia7ifCp",
        "outputId": "2383e8d8-ef03-4179-d489-fe9008bab148"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 784 into shape (5560)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9d0d5a12ca13>\u001b[0m in \u001b[0;36m<cell line: 65>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# Index of the test digit to classify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mtest_digit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mclassified_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresiduals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_digit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_digit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd_bases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Print the classification result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-9d0d5a12ca13>\u001b[0m in \u001b[0;36mclassify_digit\u001b[0;34m(test_digit, svd_bases)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdigit_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msvd_bases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Reshape the test digit to have the same number of columns as U\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mtest_digit_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_digit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Compute the residual for the current SVD basis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (5560)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_z8hS2Gg_kQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import svd\n",
        "\n",
        "# Assuming we have a function to load and preprocess the training data\n",
        "def load_training_data():\n",
        "    # Load and preprocess the training data\n",
        "    # This function should return a dictionary where the keys are digit classes (0-9)\n",
        "    # and the values are the corresponding data matrices for each class\n",
        "    pass\n",
        "\n",
        "# Assuming we have a function to load and preprocess a test digit\n",
        "def load_test_digit():\n",
        "    # Load and preprocess a test digit\n",
        "    # This function should return a flattened vector representing the test digit\n",
        "    pass\n",
        "\n",
        "# Compute the SVD for each digit class\n",
        "def compute_svd_bases(training_data):\n",
        "    svd_bases = {}\n",
        "    for digit_class, data_matrix in training_data.items():\n",
        "        U, S, Vt = svd(data_matrix, full_matrices=False)\n",
        "        svd_bases[digit_class] = (U, S, Vt)\n",
        "    return svd_bases\n",
        "\n",
        "# Classify a test digit based on the residuals in the SVD bases\n",
        "def classify_digit(test_digit, svd_bases):\n",
        "    residuals = {}\n",
        "    for digit_class, (U, S, Vt) in svd_bases.items():\n",
        "        # Compute the residual for the current SVD basis\n",
        "        residual = np.linalg.norm(test_digit - U @ (U.T @ test_digit), ord=2)\n",
        "        residuals[digit_class] = residual\n",
        "\n",
        "    # Classify the test digit based on the smallest residual\n",
        "    classified_class = min(residuals, key=residuals.get)\n",
        "    return classified_class, residuals\n",
        "\n",
        "# Main function to run the digit classification\n",
        "def main():\n",
        "    # Load the training data\n",
        "    training_data = load_training_data()\n",
        "\n",
        "    # Compute the SVD bases for each digit class\n",
        "    svd_bases = compute_svd_bases(training_data)\n",
        "\n",
        "    # Load a test digit\n",
        "    test_digit = load_test_digit()\n",
        "\n",
        "    # Classify the test digit\n",
        "    classified_class, residuals = classify_digit(test_digit, svd_bases)\n",
        "\n",
        "    # Print the classification result\n",
        "    print(f\"The digit is classified as {classified_class} with residuals: {residuals}\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}