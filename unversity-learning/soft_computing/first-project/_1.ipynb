{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfLkrNSWqogVu08Ws97t7h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Artificial_Intelligence_Learning/blob/master/_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NYiWpqOpeAmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc78592-41d5-4e69-921b-cad1ba1dc274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "[[255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " ...\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]]\n",
            "\n",
            "Bipolar Encoded Dataset:\n",
            "[[-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " ...\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Load the dataset from a text file\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    dataset = [list(map(int, line.split())) for line in lines]\n",
        "    '''\n",
        "    This line of code creates a dataset by iterating through each line in the variable `lines`,\n",
        "    splitting each line into a list of strings,\n",
        "    converting each string to an integer using the `map` function,\n",
        "    and then converting the resulting map object into a list.\n",
        "    The final dataset is a list of lists, with each inner list containing integers parsed from the original lines.\n",
        "    '''\n",
        "    return np.array(dataset)\n",
        "# Provide the correct path to your text file\n",
        "file_path = '/content/fars.txt'\n",
        "original_dataset = load_dataset(file_path)\n",
        "\n",
        "# Step 2: Convert dataset to bipolar encoding based on the specified condition\n",
        "def convert_to_bipolar_with_condition(dataset):\n",
        "    return np.where(dataset > 128, -1, 1)\n",
        "\n",
        "bipolar_dataset = convert_to_bipolar_with_condition(original_dataset)\n",
        "\n",
        "# Print original and bipolar datasets for verification\n",
        "print(\"Original Dataset:\")\n",
        "print(original_dataset)\n",
        "\n",
        "print(\"\\nBipolar Encoded Dataset:\")\n",
        "print(bipolar_dataset)\n",
        "# bipolar_dataset.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Reshape each sequence into a matrix\n",
        "num_fonts = 7\n",
        "sequence_length = 17\n",
        "\n",
        "# Reshape each sequence into a 2D matrix\n",
        "\n",
        "'''\n",
        "This line of code reshapes the original dataset into a new matrix dataset.\n",
        "The \"-1\" indicates that the first dimension of the new dataset will be inferred based on the total size of the original dataset\n",
        "and the specified number of fonts and sequence length. This reshaping is useful for preparing the data for input into a neural network,\n",
        "where the input shape may need to be specified in a certain way.\n",
        "'''\n",
        "matrix_dataset = original_dataset.reshape(-1, num_fonts, sequence_length)\n",
        "\n",
        "\n",
        "# Print the original and matrix datasets for verification\n",
        "print(\"Original Dataset:\")\n",
        "print(original_dataset)\n",
        "\n",
        "print(\"\\nMatrix Dataset:\")\n",
        "print(matrix_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACVO6l9PY1cO",
        "outputId": "38f6d0a1-3af2-4db4-f35a-7a05cf3b279c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "[[255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " ...\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]]\n",
            "\n",
            "Matrix Dataset:\n",
            "[[[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]\n",
            "\n",
            " [[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]\n",
            "\n",
            " [[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]\n",
            "\n",
            " [[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]\n",
            "\n",
            " [[255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  ...\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]\n",
            "  [255 255 255 ... 255 255 255]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Convert dataset to bipolar encoding based on the specified condition\n",
        "def convert_to_bipolar_with_condition(dataset):\n",
        "    return np.where(dataset > 128, -1, 1)\n",
        "\n",
        "bipolar_dataset = convert_to_bipolar_with_condition(original_dataset)\n",
        "\n",
        "# Step 3: Reshape each sequence into a matrix\n",
        "num_fonts = 7\n",
        "sequence_length = 17\n",
        "\n",
        "# Reshape each sequence into a 2D matrix\n",
        "matrix_dataset = bipolar_dataset.reshape(-1, num_fonts, sequence_length)\n",
        "\n",
        "# Print the original, bipolar, and matrix datasets for verification\n",
        "print(\"Original Dataset:\")\n",
        "print(original_dataset)\n",
        "\n",
        "print(\"\\nBipolar Encoded Dataset:\")\n",
        "print(bipolar_dataset)\n",
        "\n",
        "print(\"\\nMatrix Dataset:\")\n",
        "print(matrix_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6QEadIxZDeI",
        "outputId": "9e9ed7b0-5d8d-434d-c676-e32d760ce687"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Dataset:\n",
            "[[255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " ...\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]\n",
            " [255 255 255 ... 255 255 255]]\n",
            "\n",
            "Bipolar Encoded Dataset:\n",
            "[[-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " ...\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]\n",
            " [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            "Matrix Dataset:\n",
            "[[[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_characters = 17\n",
        "num_fonts = 7\n",
        "input_size = 95 * 95\n",
        "\n",
        "# Reshape each character with different fonts into a matrix\n",
        "character_matrices = bipolar_dataset.reshape(num_characters, num_fonts, 95, 95)\n",
        "\n",
        "# Flatten each matrix to create input vectors\n",
        "input_vectors = character_matrices.reshape(num_characters * num_fonts, -1)\n",
        "\n",
        "# Step 2: Build a simple perceptron network with random weights\n",
        "num_weights = input_size\n",
        "weights = np.random.randn(num_weights, 1)\n",
        "\n",
        "# Step 3: Define activation function (sigmoid) and forward pass\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def forward_pass(data, weights):\n",
        "    return sigmoid(np.dot(data, weights))\n",
        "\n",
        "# Step 4: Train the perceptron network for 10 epochs\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for char_font_idx in range(num_characters * num_fonts):\n",
        "        # Select the input vector for the current character and font\n",
        "        input_vector = input_vectors[char_font_idx, :]\n",
        "\n",
        "        # Forward pass\n",
        "        output = forward_pass(input_vector, weights)\n",
        "\n",
        "        # Convert output to bipolar (-1 or 1)\n",
        "        output_bipolar = np.where(output > 0.5, 1, -1)\n",
        "\n",
        "        # Update weights (dummy update, not based on any real learning algorithm)\n",
        "        weights += np.random.randn(num_weights, 1) * 0.01  # Adjust the learning rate as needed\n",
        "\n",
        "# Step 5: Make predictions for each character and font\n",
        "predictions = np.zeros((num_characters, num_fonts))\n",
        "\n",
        "for char_idx in range(num_characters):\n",
        "    for font_idx in range(num_fonts):\n",
        "        input_vector = input_vectors[char_idx * num_fonts + font_idx, :]\n",
        "        predictions[char_idx, font_idx] = np.where(forward_pass(input_vector, weights) > 0.5, 1, -1)\n",
        "\n",
        "# Print predictions for verification\n",
        "print(\"Predictions:\")\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvtL_HwqZZ37",
        "outputId": "7fada65a-6122-4edf-d67d-61271b5b4148"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:\n",
            "[[ 1.  1.  1.  1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1. -1.  1.  1.]\n",
            " [ 1.  1.  1.  1. -1. -1. -1.]\n",
            " [ 1.  1.  1.  1. -1. -1.  1.]\n",
            " [ 1.  1.  1.  1.  1.  1. -1.]\n",
            " [ 1.  1.  1.  1. -1. -1.  1.]\n",
            " [ 1.  1.  1.  1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1. -1.  1.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1. -1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  1.]\n",
            " [ 1.  1.  1.  1. -1.  1.  1.]\n",
            " [ 1.  1.  1. -1.  1. -1.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1.  1. -1.  1.]\n",
            " [ 1.  1.  1.  1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1.  1.  1.  1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add bias term to input vectors\n",
        "input_vectors_with_bias = np.c_[input_vectors, np.ones((num_characters * num_fonts, 1))]  # Adding a column of ones for bias\n",
        "\n",
        "# Create target labels (true if the character is present in any font)\n",
        "target_labels = np.zeros((num_characters, num_fonts))\n",
        "for char_idx in range(num_characters):\n",
        "    random_font_idx = np.random.randint(num_fonts)  # Randomly select a font for each character\n",
        "    target_labels[char_idx, random_font_idx] = 1\n",
        "target_labels = np.where(target_labels == 0, -1, 1)\n",
        "print(\"Predictions:\")\n",
        "print(predictions)\n",
        "print(\"\\nTarget Labels:\")\n",
        "print(target_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC101hd0Z-td",
        "outputId": "1026eece-a27b-42f4-d115-3a93402daa76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:\n",
            "[[ 1.  1.  1.  1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1. -1.  1.  1.]\n",
            " [ 1.  1.  1.  1. -1. -1. -1.]\n",
            " [ 1.  1.  1.  1. -1. -1.  1.]\n",
            " [ 1.  1.  1.  1.  1.  1. -1.]\n",
            " [ 1.  1.  1.  1. -1. -1.  1.]\n",
            " [ 1.  1.  1.  1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1. -1.  1.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1. -1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  1.]\n",
            " [ 1.  1.  1.  1. -1.  1.  1.]\n",
            " [ 1.  1.  1. -1.  1. -1.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1.  1. -1.  1.]\n",
            " [ 1.  1.  1.  1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1.  1.  1.  1.]]\n",
            "\n",
            "Target Labels:\n",
            "[[-1 -1  1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1  1]\n",
            " [-1  1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1  1 -1 -1 -1]\n",
            " [-1  1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1  1 -1]\n",
            " [-1 -1 -1 -1 -1 -1  1]\n",
            " [-1 -1 -1 -1 -1 -1  1]\n",
            " [-1  1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1  1 -1 -1]\n",
            " [-1 -1 -1 -1  1 -1 -1]\n",
            " [-1 -1 -1 -1  1 -1 -1]\n",
            " [ 1 -1 -1 -1 -1 -1 -1]\n",
            " [-1  1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1  1 -1]\n",
            " [-1  1 -1 -1 -1 -1 -1]\n",
            " [-1 -1 -1 -1 -1 -1  1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AT0OQYU_a8DA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}