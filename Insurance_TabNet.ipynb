{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPit6oJwRjItBxqkuZr2XFW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/DataScienceJourney/blob/master/Insurance_TabNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    matthews_corrcoef,  # Added for Matthews Correlation\n",
        "    roc_auc_score,      # Added for AUC score\n",
        "    accuracy_score      # Added for test accuracy\n",
        ")\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from xgboost import XGBRegressor\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from pytorch_tabnet.tab_model import TabNetRegressor"
      ],
      "metadata": {
        "id": "VHalzFpPozlK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load df and Explore\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify file path\n",
        "file_path = '/content/drive/My Drive/telematics_syn.csv'\n",
        "\n",
        "# Import pandas (assuming you want to use it to read the CSV)\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Display basic statistics\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T2USPsHo23n",
        "outputId": "f8fd133b-0d44-466b-eda0-5c6f7fbcf486"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   Duration  Insured.age Insured.sex  Car.age  Marital  Car.use  Credit.score  \\\n",
            "0       366           45        Male       -1  Married  Commute         609.0   \n",
            "1       182           44      Female        3  Married  Commute         575.0   \n",
            "2       184           48      Female        6  Married  Commute         847.0   \n",
            "3       183           71        Male        6  Married  Private         842.0   \n",
            "4       183           84        Male       10  Married  Private         856.0   \n",
            "\n",
            "  Region  Annual.miles.drive  Years.noclaims  ...  Left.turn.intensity10  \\\n",
            "0  Urban             6213.71              25  ...                    1.0   \n",
            "1  Urban            12427.42              20  ...                   58.0   \n",
            "2  Urban            12427.42              14  ...                    0.0   \n",
            "3  Urban             6213.71              43  ...                    0.0   \n",
            "4  Urban             6213.71              65  ...                    2.0   \n",
            "\n",
            "   Left.turn.intensity11  Left.turn.intensity12  Right.turn.intensity08  \\\n",
            "0                    0.0                    0.0                     3.0   \n",
            "1                   24.0                   11.0                  1099.0   \n",
            "2                    0.0                    0.0                     0.0   \n",
            "3                    0.0                    0.0                     0.0   \n",
            "4                    0.0                    0.0                   325.0   \n",
            "\n",
            "   Right.turn.intensity09  Right.turn.intensity10  Right.turn.intensity11  \\\n",
            "0                     1.0                     0.0                     0.0   \n",
            "1                   615.0                   219.0                   101.0   \n",
            "2                     0.0                     0.0                     0.0   \n",
            "3                     0.0                     0.0                     0.0   \n",
            "4                   111.0                    18.0                     4.0   \n",
            "\n",
            "   Right.turn.intensity12  NB_Claim    AMT_Claim  \n",
            "0                     0.0         1  5100.171753  \n",
            "1                    40.0         1   883.554840  \n",
            "2                     0.0         0     0.000000  \n",
            "3                     0.0         0     0.000000  \n",
            "4                     2.0         0     0.000000  \n",
            "\n",
            "[5 rows x 52 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 52 columns):\n",
            " #   Column                  Non-Null Count   Dtype  \n",
            "---  ------                  --------------   -----  \n",
            " 0   Duration                100000 non-null  int64  \n",
            " 1   Insured.age             100000 non-null  int64  \n",
            " 2   Insured.sex             100000 non-null  object \n",
            " 3   Car.age                 100000 non-null  int64  \n",
            " 4   Marital                 100000 non-null  object \n",
            " 5   Car.use                 100000 non-null  object \n",
            " 6   Credit.score            100000 non-null  float64\n",
            " 7   Region                  100000 non-null  object \n",
            " 8   Annual.miles.drive      100000 non-null  float64\n",
            " 9   Years.noclaims          100000 non-null  int64  \n",
            " 10  Territory               100000 non-null  int64  \n",
            " 11  Annual.pct.driven       100000 non-null  float64\n",
            " 12  Total.miles.driven      100000 non-null  float64\n",
            " 13  Pct.drive.mon           100000 non-null  float64\n",
            " 14  Pct.drive.tue           100000 non-null  float64\n",
            " 15  Pct.drive.wed           100000 non-null  float64\n",
            " 16  Pct.drive.thr           100000 non-null  float64\n",
            " 17  Pct.drive.fri           100000 non-null  float64\n",
            " 18  Pct.drive.sat           100000 non-null  float64\n",
            " 19  Pct.drive.sun           100000 non-null  float64\n",
            " 20  Pct.drive.2hrs          100000 non-null  float64\n",
            " 21  Pct.drive.3hrs          100000 non-null  float64\n",
            " 22  Pct.drive.4hrs          100000 non-null  float64\n",
            " 23  Pct.drive.wkday         100000 non-null  float64\n",
            " 24  Pct.drive.wkend         100000 non-null  float64\n",
            " 25  Pct.drive.rush am       100000 non-null  float64\n",
            " 26  Pct.drive.rush pm       100000 non-null  float64\n",
            " 27  Avgdays.week            100000 non-null  float64\n",
            " 28  Accel.06miles           100000 non-null  float64\n",
            " 29  Accel.08miles           100000 non-null  float64\n",
            " 30  Accel.09miles           100000 non-null  float64\n",
            " 31  Accel.11miles           100000 non-null  float64\n",
            " 32  Accel.12miles           100000 non-null  float64\n",
            " 33  Accel.14miles           100000 non-null  float64\n",
            " 34  Brake.06miles           100000 non-null  float64\n",
            " 35  Brake.08miles           100000 non-null  float64\n",
            " 36  Brake.09miles           100000 non-null  float64\n",
            " 37  Brake.11miles           100000 non-null  float64\n",
            " 38  Brake.12miles           100000 non-null  float64\n",
            " 39  Brake.14miles           100000 non-null  float64\n",
            " 40  Left.turn.intensity08   100000 non-null  float64\n",
            " 41  Left.turn.intensity09   100000 non-null  float64\n",
            " 42  Left.turn.intensity10   100000 non-null  float64\n",
            " 43  Left.turn.intensity11   100000 non-null  float64\n",
            " 44  Left.turn.intensity12   100000 non-null  float64\n",
            " 45  Right.turn.intensity08  100000 non-null  float64\n",
            " 46  Right.turn.intensity09  100000 non-null  float64\n",
            " 47  Right.turn.intensity10  100000 non-null  float64\n",
            " 48  Right.turn.intensity11  100000 non-null  float64\n",
            " 49  Right.turn.intensity12  100000 non-null  float64\n",
            " 50  NB_Claim                100000 non-null  int64  \n",
            " 51  AMT_Claim               100000 non-null  float64\n",
            "dtypes: float64(42), int64(6), object(4)\n",
            "memory usage: 39.7+ MB\n",
            "None\n",
            "Duration                  0\n",
            "Insured.age               0\n",
            "Insured.sex               0\n",
            "Car.age                   0\n",
            "Marital                   0\n",
            "Car.use                   0\n",
            "Credit.score              0\n",
            "Region                    0\n",
            "Annual.miles.drive        0\n",
            "Years.noclaims            0\n",
            "Territory                 0\n",
            "Annual.pct.driven         0\n",
            "Total.miles.driven        0\n",
            "Pct.drive.mon             0\n",
            "Pct.drive.tue             0\n",
            "Pct.drive.wed             0\n",
            "Pct.drive.thr             0\n",
            "Pct.drive.fri             0\n",
            "Pct.drive.sat             0\n",
            "Pct.drive.sun             0\n",
            "Pct.drive.2hrs            0\n",
            "Pct.drive.3hrs            0\n",
            "Pct.drive.4hrs            0\n",
            "Pct.drive.wkday           0\n",
            "Pct.drive.wkend           0\n",
            "Pct.drive.rush am         0\n",
            "Pct.drive.rush pm         0\n",
            "Avgdays.week              0\n",
            "Accel.06miles             0\n",
            "Accel.08miles             0\n",
            "Accel.09miles             0\n",
            "Accel.11miles             0\n",
            "Accel.12miles             0\n",
            "Accel.14miles             0\n",
            "Brake.06miles             0\n",
            "Brake.08miles             0\n",
            "Brake.09miles             0\n",
            "Brake.11miles             0\n",
            "Brake.12miles             0\n",
            "Brake.14miles             0\n",
            "Left.turn.intensity08     0\n",
            "Left.turn.intensity09     0\n",
            "Left.turn.intensity10     0\n",
            "Left.turn.intensity11     0\n",
            "Left.turn.intensity12     0\n",
            "Right.turn.intensity08    0\n",
            "Right.turn.intensity09    0\n",
            "Right.turn.intensity10    0\n",
            "Right.turn.intensity11    0\n",
            "Right.turn.intensity12    0\n",
            "NB_Claim                  0\n",
            "AMT_Claim                 0\n",
            "dtype: int64\n",
            "            Duration    Insured.age        Car.age   Credit.score  \\\n",
            "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
            "mean      314.204060      51.378950       5.639720     800.888870   \n",
            "std        79.746222      15.467075       4.062135      83.382316   \n",
            "min        27.000000      16.000000      -2.000000     422.000000   \n",
            "25%       200.000000      39.000000       2.000000     766.000000   \n",
            "50%       365.000000      51.000000       5.000000     825.000000   \n",
            "75%       366.000000      63.000000       8.000000     856.000000   \n",
            "max       366.000000     103.000000      20.000000     900.000000   \n",
            "\n",
            "       Annual.miles.drive  Years.noclaims      Territory  Annual.pct.driven  \\\n",
            "count       100000.000000   100000.000000  100000.000000      100000.000000   \n",
            "mean          9124.122908       28.839960      56.531390           0.502294   \n",
            "std           3826.144730       16.123717      24.036518           0.299189   \n",
            "min              0.000000        0.000000      11.000000           0.002740   \n",
            "25%           6213.710000       15.000000      35.000000           0.249315   \n",
            "50%           7456.452000       29.000000      62.000000           0.490411   \n",
            "75%          12427.420000       41.000000      78.000000           0.753425   \n",
            "max          56731.172300       79.000000      91.000000           1.000000   \n",
            "\n",
            "       Total.miles.driven  Pct.drive.mon  ...  Left.turn.intensity10  \\\n",
            "count       100000.000000  100000.000000  ...          100000.000000   \n",
            "mean          4833.575303       0.139365  ...             551.574010   \n",
            "std           4545.943016       0.042807  ...           14687.929802   \n",
            "min              0.095298       0.000000  ...               0.000000   \n",
            "25%           1529.897500       0.120894  ...               0.000000   \n",
            "50%           3468.287765       0.137909  ...               3.000000   \n",
            "75%           6779.876842       0.155203  ...              30.000000   \n",
            "max          47282.603936       0.998172  ...          794380.000000   \n",
            "\n",
            "       Left.turn.intensity11  Left.turn.intensity12  Right.turn.intensity08  \\\n",
            "count          100000.000000          100000.000000           100000.000000   \n",
            "mean              487.340690             447.758420              843.461830   \n",
            "std             14198.331308           13719.790281            11630.185503   \n",
            "min                 0.000000               0.000000                0.000000   \n",
            "25%                 0.000000               0.000000               11.000000   \n",
            "50%                 1.000000               0.000000              122.000000   \n",
            "75%                 9.000000               2.000000              680.000000   \n",
            "max            793926.000000          793170.000000           841210.000000   \n",
            "\n",
            "       Right.turn.intensity09  Right.turn.intensity10  Right.turn.intensity11  \\\n",
            "count           100000.000000           100000.000000           100000.000000   \n",
            "mean               565.056100              326.654840              246.713120   \n",
            "std              10657.402935             9460.244357             8977.569994   \n",
            "min                  0.000000                0.000000                0.000000   \n",
            "25%                  3.000000                0.000000                0.000000   \n",
            "50%                 43.000000                7.000000                2.000000   \n",
            "75%                321.000000               81.000000               27.000000   \n",
            "max             841207.000000           841200.000000           841176.000000   \n",
            "\n",
            "       Right.turn.intensity12      NB_Claim      AMT_Claim  \n",
            "count           100000.000000  100000.00000  100000.000000  \n",
            "mean               198.753690       0.04494     137.602253  \n",
            "std               8585.177049       0.21813    1264.320056  \n",
            "min                  0.000000       0.00000       0.000000  \n",
            "25%                  0.000000       0.00000       0.000000  \n",
            "50%                  0.000000       0.00000       0.000000  \n",
            "75%                  9.000000       0.00000       0.000000  \n",
            "max             841144.000000       3.00000  104074.886700  \n",
            "\n",
            "[8 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove samples with AMT_Claim = 0\n",
        "df = df[df['AMT_Claim'] > 0]\n",
        "\n",
        "# Data Preprocessing\n",
        "categorical_columns = ['Insured.sex', 'Marital', 'Car.use', 'Region']\n",
        "numerical_columns = [col for col in df.columns if col not in categorical_columns + ['AMT_Claim']]\n",
        "\n",
        "# Feature Engineering\n",
        "def aggregate_harsh_driving(df):\n",
        "    df['total_accel'] = df[[col for col in df.columns if col.startswith('Accel')]].sum(axis=1)\n",
        "    df['total_brake'] = df[[col for col in df.columns if col.startswith('Brake')]].sum(axis=1)\n",
        "    df['total_left_turn'] = df[[col for col in df.columns if col.startswith('Left.turn')]].sum(axis=1)\n",
        "    df['total_right_turn'] = df[[col for col in df.columns if col.startswith('Right.turn')]].sum(axis=1)\n",
        "    return df\n",
        "\n",
        "df = aggregate_harsh_driving(df)\n",
        "\n",
        "# Split the data\n",
        "X = df.drop('AMT_Claim', axis=1)\n",
        "y = df['AMT_Claim']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocessing\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_columns),\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ])\n",
        "\n",
        "# Fit the preprocessor and transform the data\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# Get the number of features after preprocessing\n",
        "n_features = X_train_processed.shape[1]\n"
      ],
      "metadata": {
        "id": "F7iWYwAaq5cN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the FJ model (DNN + TabNet + XGBoost)\n",
        "class FJModel:\n",
        "    def __init__(self, input_dim):\n",
        "        self.dnn = self._build_dnn(input_dim)\n",
        "        self.tabnet = TabNetRegressor()\n",
        "        self.xgb = XGBRegressor(random_state=42)\n",
        "\n",
        "    def _build_dnn(self, input_dim):\n",
        "        inputs = Input(shape=(input_dim,))\n",
        "        x = Dense(64, activation='relu')(inputs)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        outputs = Dense(1)(x)\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(optimizer=Adam(), loss='mse')\n",
        "        return model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.dnn.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
        "        self.tabnet.fit(X.toarray() if hasattr(X, 'toarray') else X, y)\n",
        "        self.xgb.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        dnn_pred = self.dnn.predict(X).flatten()\n",
        "        tabnet_pred = self.tabnet.predict(X.toarray() if hasattr(X, 'toarray') else X).flatten()\n",
        "        xgb_pred = self.xgb.predict(X)\n",
        "        return (dnn_pred + tabnet_pred + xgb_pred) / 3\n",
        "\n",
        "# Initialize and train the model\n",
        "model = FJModel(n_features)\n",
        "model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_processed)\n",
        "\n",
        "# Calculate metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R-squared Score: {r2}\")\n",
        "\n",
        "# Feature Importance (using XGBoost as a proxy)\n",
        "feature_importance = model.xgb.feature_importances_\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
        "importance_df = importance_df.sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"Top 10 Most Important Features:\")\n",
        "print(importance_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "HXDqcURnwuov",
        "outputId": "c601d2c0-a693-43fd-ad28-f8fe79286e27"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Targets should be 2D : (n_samples, n_regression) but y_train.shape=(3091,) given.\nUse reshape(-1, 1) for single regression.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-746b4f064c4a>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Initialize and train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFJModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-746b4f064c4a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'toarray'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mcheck_warm_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_unsupervised\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         self.update_fit_params(\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_tabnet/tab_model.py\u001b[0m in \u001b[0;36mupdate_fit_params\u001b[0;34m(self, X_train, y_train, eval_set, weights)\u001b[0m\n\u001b[1;32m    139\u001b[0m                   \u001b[0;34mf\"but y_train.shape={y_train.shape} given.\\n\"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                   \u001b[0;34m\"Use reshape(-1, 1) for single regression.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Targets should be 2D : (n_samples, n_regression) but y_train.shape=(3091,) given.\nUse reshape(-1, 1) for single regression."
          ]
        }
      ]
    }
  ]
}