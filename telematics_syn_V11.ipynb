{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/DataScienceJourney/blob/master/telematics_syn_V11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlKvn7dGihG5",
        "outputId": "88dc3d11-bc97-43aa-b57c-67b849a12cc3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Step 1: Load the dataset\n",
        "dataset = pd.read_csv('/content/drive/My Drive/telematics_syn.csv')"
      ],
      "metadata": {
        "id": "WjZiBMQ_iooq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "4HYlQKONmiuw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Create the adjusted ClaimYN label\n",
        "dataset['ClaimYN'] = ((dataset['NB_Claim'] >= 1) & (dataset['AMT_Claim'] > 1000)).astype(int)\n",
        "\n",
        "# Preprocess the dataset\n",
        "# 1. Handle missing values\n",
        "dataset.fillna(method='ffill', inplace=True)  # Simple forward fill for missing values\n",
        "\n",
        "# 2. Encode categorical variables (if any exist)\n",
        "categorical_columns = dataset.select_dtypes(include=['object']).columns\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    dataset[col] = le.fit_transform(dataset[col])\n",
        "\n",
        "# 3. Standardize numerical columns\n",
        "numerical_columns = dataset.drop(columns=['ClaimYN', 'NB_Claim', 'AMT_Claim']).columns\n",
        "scaler = StandardScaler()\n",
        "dataset[numerical_columns] = scaler.fit_transform(dataset[numerical_columns])\n",
        "\n",
        "# Handle the imbalance in the dataset using SMOTE\n",
        "X = dataset.drop(columns=['ClaimYN'])\n",
        "y = dataset['ClaimYN']\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Merging resampled data back into a single DataFrame\n",
        "dataset_resampled = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "\n",
        "# Drop NB_Claim and AMT_Claim columns\n",
        "dataset_resampled = dataset_resampled.drop(columns=['NB_Claim', 'AMT_Claim'])\n",
        "\n",
        "# Split the dataset into train, test, and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = dataset_resampled.drop(columns=['ClaimYN'])\n",
        "y = dataset_resampled['ClaimYN']\n",
        "\n",
        "# Split the data (70% train, 15% test, 15% validation)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Testing set size: {len(X_test)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d87ORJ_liX6x",
        "outputId": "5a36bc3b-ad7d-418c-e201-e3c92af23345"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 136222\n",
            "Testing set size: 29191\n",
            "Validation set size: 29191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "log_reg = LogisticRegression(random_state=42, max_iter=200)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = log_reg.predict(X_test)\n",
        "print(\"Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVjhONWfjrkw",
        "outputId": "dfcdad71-8121-4a67-c882-97b93d47eff0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.72      0.75     14593\n",
            "           1       0.74      0.80      0.77     14598\n",
            "\n",
            "    accuracy                           0.76     29191\n",
            "   macro avg       0.76      0.76      0.76     29191\n",
            "weighted avg       0.76      0.76      0.76     29191\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6TpqdIflVwd",
        "outputId": "2bf2751c-291f-4db6-f791-8c9df729c6ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99     14593\n",
            "           1       1.00      0.98      0.99     14598\n",
            "\n",
            "    accuracy                           0.99     29191\n",
            "   macro avg       0.99      0.99      0.99     29191\n",
            "weighted avg       0.99      0.99      0.99     29191\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = xgb.predict(X_test)\n",
        "print(\"XGBoost Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YIHzFpone0q",
        "outputId": "25c5d849-6242-4f5f-8ba1-c31f0b9d0aa7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99     14593\n",
            "           1       1.00      0.98      0.99     14598\n",
            "\n",
            "    accuracy                           0.99     29191\n",
            "   macro avg       0.99      0.99      0.99     29191\n",
            "weighted avg       0.99      0.99      0.99     29191\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAHHElrJoA58",
        "outputId": "bdb13ec2-bb1e-4fdb-cd31-31e2f3e08be5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.26.4)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.3.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch_tabnet) (4.66.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch_tabnet) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch_tabnet) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch_tabnet\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pytorch_tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Convert data to numpy arrays for TabNet\n",
        "X_train_np, y_train_np = X_train.values, y_train.values\n",
        "X_test_np, y_test_np = X_test.values, y_test.values\n",
        "\n",
        "# Initialize and train the TabNet model\n",
        "tabnet = TabNetClassifier(seed=42)\n",
        "tabnet.fit(X_train_np, y_train_np, eval_set=[(X_test_np, y_test_np)], patience=10)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = np.argmax(tabnet.predict_proba(X_test_np), axis=1)\n",
        "print(\"TabNet Classification Report:\")\n",
        "print(classification_report(y_test_np, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6leXUTFoDoA",
        "outputId": "4947ad19-3922-4bfe-9c32-7969926f5f1c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.52451 | val_0_auc: 0.87515 |  0:00:15s\n",
            "epoch 1  | loss: 0.43317 | val_0_auc: 0.89764 |  0:00:20s\n",
            "epoch 2  | loss: 0.39164 | val_0_auc: 0.92828 |  0:00:28s\n",
            "epoch 3  | loss: 0.34    | val_0_auc: 0.94508 |  0:00:33s\n",
            "epoch 4  | loss: 0.31046 | val_0_auc: 0.95073 |  0:00:41s\n",
            "epoch 5  | loss: 0.28787 | val_0_auc: 0.96103 |  0:00:47s\n",
            "epoch 6  | loss: 0.27042 | val_0_auc: 0.962   |  0:00:54s\n",
            "epoch 7  | loss: 0.26094 | val_0_auc: 0.96252 |  0:01:00s\n",
            "epoch 8  | loss: 0.25302 | val_0_auc: 0.96613 |  0:01:06s\n",
            "epoch 9  | loss: 0.24544 | val_0_auc: 0.96825 |  0:01:12s\n",
            "epoch 10 | loss: 0.23994 | val_0_auc: 0.97131 |  0:01:19s\n",
            "epoch 11 | loss: 0.23557 | val_0_auc: 0.96242 |  0:01:25s\n",
            "epoch 12 | loss: 0.22619 | val_0_auc: 0.96915 |  0:01:32s\n",
            "epoch 13 | loss: 0.22559 | val_0_auc: 0.96316 |  0:01:38s\n",
            "epoch 14 | loss: 0.21921 | val_0_auc: 0.97498 |  0:01:47s\n",
            "epoch 15 | loss: 0.21526 | val_0_auc: 0.9745  |  0:01:53s\n",
            "epoch 16 | loss: 0.21137 | val_0_auc: 0.97374 |  0:02:00s\n",
            "epoch 17 | loss: 0.21189 | val_0_auc: 0.97562 |  0:02:06s\n",
            "epoch 18 | loss: 0.21145 | val_0_auc: 0.97257 |  0:02:13s\n",
            "epoch 19 | loss: 0.20618 | val_0_auc: 0.96458 |  0:02:19s\n",
            "epoch 20 | loss: 0.20369 | val_0_auc: 0.97169 |  0:02:25s\n",
            "epoch 21 | loss: 0.20056 | val_0_auc: 0.97665 |  0:02:32s\n",
            "epoch 22 | loss: 0.20625 | val_0_auc: 0.96594 |  0:02:38s\n",
            "epoch 23 | loss: 0.19931 | val_0_auc: 0.96531 |  0:02:45s\n",
            "epoch 24 | loss: 0.20434 | val_0_auc: 0.96378 |  0:02:51s\n",
            "epoch 25 | loss: 0.21298 | val_0_auc: 0.96297 |  0:02:58s\n",
            "epoch 26 | loss: 0.21783 | val_0_auc: 0.96301 |  0:03:04s\n",
            "epoch 27 | loss: 0.21867 | val_0_auc: 0.97427 |  0:03:11s\n",
            "epoch 28 | loss: 0.20036 | val_0_auc: 0.9572  |  0:03:17s\n",
            "epoch 29 | loss: 0.19617 | val_0_auc: 0.97778 |  0:03:24s\n",
            "epoch 30 | loss: 0.20589 | val_0_auc: 0.97139 |  0:03:30s\n",
            "epoch 31 | loss: 0.19946 | val_0_auc: 0.93818 |  0:03:37s\n",
            "epoch 32 | loss: 0.19635 | val_0_auc: 0.96305 |  0:03:43s\n",
            "epoch 33 | loss: 0.18932 | val_0_auc: 0.97071 |  0:03:50s\n",
            "epoch 34 | loss: 0.20191 | val_0_auc: 0.92974 |  0:03:55s\n",
            "epoch 35 | loss: 0.18758 | val_0_auc: 0.94984 |  0:04:02s\n",
            "epoch 36 | loss: 0.18522 | val_0_auc: 0.95398 |  0:04:08s\n",
            "epoch 37 | loss: 0.18305 | val_0_auc: 0.9475  |  0:04:15s\n",
            "epoch 38 | loss: 0.19342 | val_0_auc: 0.96845 |  0:04:21s\n",
            "epoch 39 | loss: 0.1973  | val_0_auc: 0.955   |  0:04:28s\n",
            "\n",
            "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.97778\n",
            "TabNet Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.80      0.87     14593\n",
            "           1       0.83      0.97      0.89     14598\n",
            "\n",
            "    accuracy                           0.88     29191\n",
            "   macro avg       0.90      0.88      0.88     29191\n",
            "weighted avg       0.90      0.88      0.88     29191\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Reshape data for RNN (3D input: samples, timesteps, features)\n",
        "X_train_rnn = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_val_rnn = X_val.values.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
        "X_test_rnn = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Initialize the RNN model\n",
        "rnn_model = Sequential()\n",
        "rnn_model.add(SimpleRNN(32, input_shape=(X_train_rnn.shape[1], 1), activation='relu'))\n",
        "rnn_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "rnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "rnn_history = rnn_model.fit(X_train_rnn, y_train, epochs=50, batch_size=32,\n",
        "                            validation_data=(X_val_rnn, y_val), verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = rnn_model.evaluate(X_test_rnn, y_test)\n",
        "print(f\"RNN Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU2SkBz0sr3N",
        "outputId": "792b29be-fe38-4622-dcec-efbb92c95413"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 10ms/step - accuracy: 0.6756 - loss: 0.6066 - val_accuracy: 0.7629 - val_loss: 0.4695\n",
            "Epoch 2/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 9ms/step - accuracy: 0.8018 - loss: 0.4254 - val_accuracy: 0.8215 - val_loss: 0.4088\n",
            "Epoch 3/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8370 - loss: 0.3563 - val_accuracy: 0.8264 - val_loss: 0.4639\n",
            "Epoch 4/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8657 - loss: 0.3049 - val_accuracy: 0.8742 - val_loss: 0.2848\n",
            "Epoch 5/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 9ms/step - accuracy: 0.8730 - loss: 0.2857 - val_accuracy: 0.8830 - val_loss: 0.2597\n",
            "Epoch 6/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9ms/step - accuracy: 0.8797 - loss: 0.2714 - val_accuracy: 0.8627 - val_loss: 0.3100\n",
            "Epoch 7/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8829 - loss: 0.2641 - val_accuracy: 0.8895 - val_loss: 0.2575\n",
            "Epoch 8/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8877 - loss: 0.2546 - val_accuracy: 0.8973 - val_loss: 0.2316\n",
            "Epoch 9/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8912 - loss: 0.2468 - val_accuracy: 0.8999 - val_loss: 0.2282\n",
            "Epoch 10/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 9ms/step - accuracy: 0.8941 - loss: 0.2410 - val_accuracy: 0.8950 - val_loss: 0.2410\n",
            "Epoch 11/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 8ms/step - accuracy: 0.8942 - loss: 0.2387 - val_accuracy: 0.8749 - val_loss: 0.2978\n",
            "Epoch 12/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8960 - loss: 0.2374 - val_accuracy: 0.9066 - val_loss: 0.2194\n",
            "Epoch 13/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8997 - loss: 0.2289 - val_accuracy: 0.9023 - val_loss: 0.2260\n",
            "Epoch 14/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8962 - loss: 0.2323 - val_accuracy: 0.9062 - val_loss: 0.2167\n",
            "Epoch 15/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.9031 - loss: 0.2242 - val_accuracy: 0.8994 - val_loss: 0.2250\n",
            "Epoch 16/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.9022 - loss: 0.2216 - val_accuracy: 0.9145 - val_loss: 0.2015\n",
            "Epoch 17/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9035 - loss: 0.2238 - val_accuracy: 0.8987 - val_loss: 0.2263\n",
            "Epoch 18/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9047 - loss: 0.2209 - val_accuracy: 0.9106 - val_loss: 0.2071\n",
            "Epoch 19/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.9023 - loss: 0.2235 - val_accuracy: 0.9037 - val_loss: 0.2141\n",
            "Epoch 20/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 9ms/step - accuracy: 0.8994 - loss: 0.2298 - val_accuracy: 0.9071 - val_loss: 0.2147\n",
            "Epoch 21/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 9ms/step - accuracy: 0.9043 - loss: 0.2173 - val_accuracy: 0.9120 - val_loss: 0.2180\n",
            "Epoch 22/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.9011 - loss: 0.2243 - val_accuracy: 0.9022 - val_loss: 0.2158\n",
            "Epoch 23/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.9031 - loss: 0.2202 - val_accuracy: 0.9003 - val_loss: 0.2333\n",
            "Epoch 24/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9056 - loss: 0.2164 - val_accuracy: 0.9056 - val_loss: 0.2134\n",
            "Epoch 25/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 9ms/step - accuracy: 0.9040 - loss: 0.2201 - val_accuracy: 0.8999 - val_loss: 0.2200\n",
            "Epoch 26/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 9ms/step - accuracy: 0.9032 - loss: 0.2218 - val_accuracy: 0.8980 - val_loss: 0.2259\n",
            "Epoch 27/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 9ms/step - accuracy: 0.9024 - loss: 0.2249 - val_accuracy: 0.8728 - val_loss: 0.2615\n",
            "Epoch 28/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8967 - loss: 0.2355 - val_accuracy: 0.8659 - val_loss: 0.2965\n",
            "Epoch 29/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8744 - loss: 0.2832 - val_accuracy: 0.8947 - val_loss: 0.2348\n",
            "Epoch 30/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.8999 - loss: 0.2291 - val_accuracy: 0.8952 - val_loss: 0.2305\n",
            "Epoch 31/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.9043 - loss: 0.2184 - val_accuracy: 0.9081 - val_loss: 0.2083\n",
            "Epoch 32/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.8988 - loss: 0.2317 - val_accuracy: 0.8955 - val_loss: 0.2348\n",
            "Epoch 33/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8094 - loss: 0.4028 - val_accuracy: 0.8780 - val_loss: 0.2717\n",
            "Epoch 34/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.8752 - loss: 0.2864 - val_accuracy: 0.8769 - val_loss: 0.2939\n",
            "Epoch 35/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8825 - loss: 0.2748 - val_accuracy: 0.8864 - val_loss: 0.2565\n",
            "Epoch 36/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8791 - loss: 0.2807 - val_accuracy: 0.8830 - val_loss: 0.2744\n",
            "Epoch 37/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9ms/step - accuracy: 0.8875 - loss: 0.2606 - val_accuracy: 0.8934 - val_loss: 0.2406\n",
            "Epoch 38/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - accuracy: 0.8938 - loss: 0.2457 - val_accuracy: 0.8688 - val_loss: 0.3437\n",
            "Epoch 39/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 9ms/step - accuracy: 0.8967 - loss: 0.2378 - val_accuracy: 0.8741 - val_loss: 0.2836\n",
            "Epoch 40/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 9ms/step - accuracy: 0.8953 - loss: 0.2395 - val_accuracy: 0.8884 - val_loss: 0.2520\n",
            "Epoch 41/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8928 - loss: 0.2450 - val_accuracy: 0.8974 - val_loss: 0.2284\n",
            "Epoch 42/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.9011 - loss: 0.2280 - val_accuracy: 0.8975 - val_loss: 0.2280\n",
            "Epoch 43/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8978 - loss: 0.2341 - val_accuracy: 0.9059 - val_loss: 0.2213\n",
            "Epoch 44/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8954 - loss: 0.2427 - val_accuracy: 0.8974 - val_loss: 0.2317\n",
            "Epoch 45/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.8861 - loss: 0.2693 - val_accuracy: 0.8927 - val_loss: 0.2496\n",
            "Epoch 46/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8ms/step - accuracy: 0.8965 - loss: 0.2391 - val_accuracy: 0.8847 - val_loss: 0.2638\n",
            "Epoch 47/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8880 - loss: 0.2556 - val_accuracy: 0.9009 - val_loss: 0.2311\n",
            "Epoch 48/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.8953 - loss: 0.2432 - val_accuracy: 0.9009 - val_loss: 0.2278\n",
            "Epoch 49/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - accuracy: 0.8794 - loss: 0.2752 - val_accuracy: 0.8897 - val_loss: 0.2445\n",
            "Epoch 50/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.8954 - loss: 0.2422 - val_accuracy: 0.9033 - val_loss: 0.2210\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9040 - loss: 0.2235\n",
            "RNN Test Accuracy: 0.9039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
        "\n",
        "# Initialize the CNN model\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_rnn.shape[1], 1)))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "cnn_history = cnn_model.fit(X_train_rnn, y_train, epochs=50, batch_size=32,\n",
        "                            validation_data=(X_val_rnn, y_val), verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = cnn_model.evaluate(X_test_rnn, y_test)\n",
        "print(f\"CNN Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "VM9j_CCNwLMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbada4c7-b2b9-4080-f4c4-ebbf28613589"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8103 - loss: 0.4161 - val_accuracy: 0.8547 - val_loss: 0.3262\n",
            "Epoch 2/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.8563 - loss: 0.3241 - val_accuracy: 0.8621 - val_loss: 0.3132\n",
            "Epoch 3/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3015 - val_accuracy: 0.8680 - val_loss: 0.2962\n",
            "Epoch 4/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8747 - loss: 0.2873 - val_accuracy: 0.8744 - val_loss: 0.2837\n",
            "Epoch 5/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8783 - loss: 0.2776 - val_accuracy: 0.8819 - val_loss: 0.2757\n",
            "Epoch 6/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.2683 - val_accuracy: 0.8849 - val_loss: 0.2622\n",
            "Epoch 7/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.2582 - val_accuracy: 0.8816 - val_loss: 0.2599\n",
            "Epoch 8/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8916 - loss: 0.2512 - val_accuracy: 0.8908 - val_loss: 0.2633\n",
            "Epoch 9/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.2495 - val_accuracy: 0.8822 - val_loss: 0.2575\n",
            "Epoch 10/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.2436 - val_accuracy: 0.8960 - val_loss: 0.2416\n",
            "Epoch 11/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.2382 - val_accuracy: 0.8964 - val_loss: 0.2359\n",
            "Epoch 12/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.2340 - val_accuracy: 0.9012 - val_loss: 0.2335\n",
            "Epoch 13/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.2321 - val_accuracy: 0.9004 - val_loss: 0.2306\n",
            "Epoch 14/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2299 - val_accuracy: 0.8998 - val_loss: 0.2279\n",
            "Epoch 15/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9046 - loss: 0.2253 - val_accuracy: 0.8974 - val_loss: 0.2284\n",
            "Epoch 16/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.2265 - val_accuracy: 0.9009 - val_loss: 0.2255\n",
            "Epoch 17/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2233 - val_accuracy: 0.9014 - val_loss: 0.2297\n",
            "Epoch 18/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.2221 - val_accuracy: 0.9040 - val_loss: 0.2281\n",
            "Epoch 19/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2156 - val_accuracy: 0.9053 - val_loss: 0.2182\n",
            "Epoch 20/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2176 - val_accuracy: 0.9000 - val_loss: 0.2260\n",
            "Epoch 21/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2171 - val_accuracy: 0.9072 - val_loss: 0.2189\n",
            "Epoch 22/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2141 - val_accuracy: 0.9040 - val_loss: 0.2183\n",
            "Epoch 23/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2128 - val_accuracy: 0.9035 - val_loss: 0.2185\n",
            "Epoch 24/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2109 - val_accuracy: 0.9086 - val_loss: 0.2137\n",
            "Epoch 25/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2118 - val_accuracy: 0.9081 - val_loss: 0.2138\n",
            "Epoch 26/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2102 - val_accuracy: 0.9040 - val_loss: 0.2166\n",
            "Epoch 27/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2071 - val_accuracy: 0.9041 - val_loss: 0.2171\n",
            "Epoch 28/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2091 - val_accuracy: 0.9081 - val_loss: 0.2113\n",
            "Epoch 29/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2051 - val_accuracy: 0.9090 - val_loss: 0.2092\n",
            "Epoch 30/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2064 - val_accuracy: 0.9111 - val_loss: 0.2098\n",
            "Epoch 31/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2040 - val_accuracy: 0.9072 - val_loss: 0.2104\n",
            "Epoch 32/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2046 - val_accuracy: 0.9096 - val_loss: 0.2283\n",
            "Epoch 33/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2043 - val_accuracy: 0.9130 - val_loss: 0.2044\n",
            "Epoch 34/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2007 - val_accuracy: 0.9135 - val_loss: 0.2028\n",
            "Epoch 35/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2041 - val_accuracy: 0.8931 - val_loss: 0.2312\n",
            "Epoch 36/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2023 - val_accuracy: 0.9136 - val_loss: 0.2008\n",
            "Epoch 37/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2011 - val_accuracy: 0.9126 - val_loss: 0.2022\n",
            "Epoch 38/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2017 - val_accuracy: 0.9133 - val_loss: 0.2061\n",
            "Epoch 39/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.1997 - val_accuracy: 0.9061 - val_loss: 0.2085\n",
            "Epoch 40/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2006 - val_accuracy: 0.9037 - val_loss: 0.2174\n",
            "Epoch 41/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.1980 - val_accuracy: 0.9026 - val_loss: 0.2170\n",
            "Epoch 42/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.1974 - val_accuracy: 0.9137 - val_loss: 0.2101\n",
            "Epoch 43/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.1992 - val_accuracy: 0.9130 - val_loss: 0.1989\n",
            "Epoch 44/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.1997 - val_accuracy: 0.9125 - val_loss: 0.1981\n",
            "Epoch 45/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.1956 - val_accuracy: 0.9145 - val_loss: 0.1998\n",
            "Epoch 46/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.1958 - val_accuracy: 0.9130 - val_loss: 0.1992\n",
            "Epoch 47/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.1968 - val_accuracy: 0.9157 - val_loss: 0.2012\n",
            "Epoch 48/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.1937 - val_accuracy: 0.9156 - val_loss: 0.1967\n",
            "Epoch 49/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.1916 - val_accuracy: 0.9041 - val_loss: 0.2086\n",
            "Epoch 50/50\n",
            "\u001b[1m4257/4257\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.1939 - val_accuracy: 0.9100 - val_loss: 0.2188\n",
            "\u001b[1m913/913\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2174\n",
            "CNN Test Accuracy: 0.9085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM\n",
        "\n",
        "# Initialize the LSTM model\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(32, input_shape=(X_train_rnn.shape[1], 1), activation='relu'))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "lstm_history = lstm_model.fit(X_train_rnn, y_train, epochs=50, batch_size=32,\n",
        "                              validation_data=(X_val_rnn, y_val), verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = lstm_model.evaluate(X_test_rnn, y_test)\n",
        "print(f\"LSTM Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "btCePnE0xr8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import GRU\n",
        "\n",
        "# Initialize the GRU model\n",
        "gru_model = Sequential()\n",
        "gru_model.add(GRU(32, input_shape=(X_train_rnn.shape[1], 1), activation='relu'))\n",
        "gru_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "gru_history = gru_model.fit(X_train_rnn, y_train, epochs=50, batch_size=32,\n",
        "                            validation_data=(X_val_rnn, y_val), verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = gru_model.evaluate(X_test_rnn, y_test)\n",
        "print(f\"GRU Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "O4bAZxp3CVM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Necessary Libraries for Evaluation"
      ],
      "metadata": {
        "id": "nLHsydXCJia6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ensure you have seaborn for nicer plots\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "metadata": {
        "id": "jyz0mK1PCV5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_true, y_pred, y_pred_proba, model_name):\n",
        "    \"\"\"Evaluate the model using MCC, AUC, and plot the confusion matrix.\"\"\"\n",
        "\n",
        "    # Calculate MCC\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "\n",
        "    # Calculate AUC\n",
        "    auc = roc_auc_score(y_true, y_pred_proba)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"{model_name} Evaluation:\")\n",
        "    print(f\"  MCC: {mcc:.4f}\")\n",
        "    print(f\"  AUC: {auc:.4f}\")\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f'{model_name} Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "def plot_training_history(history, model_name):\n",
        "    \"\"\"Plot training & validation accuracy and loss from the model's history.\"\"\"\n",
        "    # Accuracy\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title(f'{model_name} Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{model_name} Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "x5p6WJI0Jro-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities for AUC calculation\n",
        "y_pred_proba_log_reg = log_reg.predict_proba(X_test)[:, 1]\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "evaluate_model(y_test, y_pred_log_reg, y_pred_proba_log_reg, \"Logistic Regression\")"
      ],
      "metadata": {
        "id": "JAevIieFJ6WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities for AUC calculation\n",
        "y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "evaluate_model(y_test, y_pred_rf, y_pred_proba_rf, \"Random Forest\")"
      ],
      "metadata": {
        "id": "cNDQEX6qKP9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities for AUC calculation\n",
        "y_pred_proba_xgb = xgb.predict_proba(X_test)[:, 1]\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "# Evaluate the XGBoost model\n",
        "evaluate_model(y_test, y_pred_xgb, y_pred_proba_xgb, \"XGBoost\")"
      ],
      "metadata": {
        "id": "nO9u-ufrKeGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities for AUC calculation\n",
        "y_pred_proba_tabnet = tabnet.predict_proba(X_test_np)[:, 1]\n",
        "y_pred_tabnet = np.argmax(tabnet.predict_proba(X_test_np), axis=1)\n",
        "\n",
        "# Evaluate the TabNet model\n",
        "evaluate_model(y_test_np, y_pred_tabnet, y_pred_proba_tabnet, \"TabNet\")"
      ],
      "metadata": {
        "id": "8JfxF7spKtuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the RNN model\n",
        "y_pred_proba_rnn = rnn_model.predict(X_test_rnn).flatten()\n",
        "y_pred_rnn = (y_pred_proba_rnn > 0.5).astype(int)\n",
        "\n",
        "evaluate_model(y_test, y_pred_rnn, y_pred_proba_rnn, \"RNN\")\n",
        "plot_training_history(rnn_history, \"RNN\")"
      ],
      "metadata": {
        "id": "ojkaK1VCLIns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the RNN model\n",
        "rnn_history = rnn_model.fit(X_train_rnn, y_train, epochs=100, batch_size=32,\n",
        "                            validation_data=(X_val_rnn, y_val), verbose=1)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_proba_rnn = rnn_model.predict(X_test_rnn).flatten()\n",
        "y_pred_rnn = (y_pred_proba_rnn > 0.5).astype(int)\n",
        "\n",
        "# Evaluate RNN model\n",
        "evaluate_model(y_test, y_pred_rnn, y_pred_proba_rnn, \"RNN\")\n",
        "\n",
        "# Plot training and validation history\n",
        "plot_training_history(rnn_history, \"RNN\")"
      ],
      "metadata": {
        "id": "qMBNlhgxL1d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the CNN model\n",
        "cnn_history = cnn_model.fit(X_train_rnn, y_train, epochs=50, batch_size=32,\n",
        "                            validation_data=(X_val_rnn, y_val), verbose=1)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_proba_cnn = cnn_model.predict(X_test_rnn).flatten()\n",
        "y_pred_cnn = (y_pred_proba_cnn > 0.5).astype(int)\n",
        "\n",
        "# Evaluate CNN model\n",
        "evaluate_model(y_test, y_pred_cnn, y_pred_proba_cnn, \"CNN\")\n",
        "\n",
        "# Plot training and validation history\n",
        "plot_training_history(cnn_history, \"CNN\")"
      ],
      "metadata": {
        "id": "5sRUSER0PQal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the LSTM model\n",
        "lstm_history = lstm_model.fit(X_train_rnn, y_train, epochs=50, batch_size=32,\n",
        "                              validation_data=(X_val_rnn, y_val), verbose=1)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_proba_lstm = lstm_model.predict(X_test_rnn).flatten()\n",
        "y_pred_lstm = (y_pred_proba_lstm > 0.5).astype(int)\n",
        "\n",
        "# Evaluate LSTM model\n",
        "evaluate_model(y_test, y_pred_lstm, y_pred_proba_lstm, \"LSTM\")\n",
        "\n",
        "# Plot training and validation history\n",
        "plot_training_history(lstm_history, \"LSTM\")"
      ],
      "metadata": {
        "id": "2WNjAyiHQU_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the GRU model\n",
        "gru_history = gru_model.fit(X_train_rnn, y_train, epochs=50, batch_size=32,\n",
        "                            validation_data=(X_val_rnn, y_val), verbose=1)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_proba_gru = gru_model.predict(X_test_rnn).flatten()\n",
        "y_pred_gru = (y_pred_proba_gru > 0.5).astype(int)\n",
        "\n",
        "# Evaluate GRU model\n",
        "evaluate_model(y_test, y_pred_gru, y_pred_proba_gru, \"GRU\")\n",
        "\n",
        "# Plot training and validation history\n",
        "plot_training_history(gru_history, \"GRU\")\n"
      ],
      "metadata": {
        "id": "dg_KvsBmVBCl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}